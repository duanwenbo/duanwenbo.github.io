[{"content":"What is Option Trading ?\nA security giving the right to buy or sell an asset, subject to certain conditions, with a specified period of time.\nStrike Price 行权价； Premium 期权价；\nEuropean Option: Exercisable only on the expiration date. American Option: Can be exercised at any time before the expiration date.\nWhen the stock price is much greater than theexercise price, the option is almost sure to be exercised. The current value ofthe option will thus be approximately equal to the price of the stock minusthe price of a pure discount bond that matures on the same date as theoption, with a face value equal to the striking price of the option.\nThe current value of option = current stock price - strike Price value as of today Option Value = ReLU(Asset Price - Strike Price * Discounted Factor) strike Price value as of today can be represented by a zero-coupon bond, with a face value same as strike price and same maturity date. Black Schole Formula:\nA standarlized way to price the option.\nThe model is based on Geometric Brownian Motion, a stochastic differential equation used to represent a random process, the theory is derived from the Delta Hedging hypothesis.\nFor a Eupropean style call Option, the price/premium of the option is described as $$ C =N(d_1)S_t - N(d_2)Ke^{-rt} $$ Where: $$ d_1 = \\frac{In\\frac{s_t}{K}+(r+\\frac{\\sigma^2}{2})t}{\\sigma\\sqrt{t}} $$\n$$ d_2 = d_1 -\\sigma\\sqrt{t} $$\nC: option preimum\nS_t: Spot price of underlying asset\nK: Strike Price\nr: risk free interest rate\nt: time to matuirty\nSigma: volatility\nMoneyness, ITM, ATM and OTM:\nMoneyness is used to describe the intrinsic value, regardless of absolute strike price and underlying price:\nIn-the-Money (ITM): Call: S\u0026gt;KS\u0026gt;K (e.g., S=100S=100, K=90K=90 → intrinsic value = $10). Put: S\u0026lt;KS\u0026lt;K (e.g., S=100S=100, K=110K=110 → intrinsic value = $10). At-the-Money (ATM): S≈KS≈K (intrinsic value ≈ $0). Out-of-the-Money (OTM): Call: S\u0026lt;K; Put: S\u0026gt;K, (intrinsic value = $0). Quantifying Moneyness Simple Ratio:\nCall: S/KS/K; Put: K/SK/S. Values \u0026gt;1 indicate ITM for calls (OTM for puts). Log-Normalized Measure:\nMoneyness=ln⁡(S/K)σTMoneyness=σ**Tln(S/K)\nStandardizes price deviation for volatility modeling.\nVolatility and Volatility Surface:\nIn theory, BS Model assumes volatility as a constant.i.e. $\\sigma \\in N$, for example, we have two call options on the same underlying future contract, but with different strike. These two options should have the same volatility. HOWEVER, $\\sigma$ changes with strike and time in the real market, when pricing the option, we usually derive the volatility from the historical market data, this is called implied volatility, i.e. $\\sigma = f(K,T)$\nThe different patterns of vol (volatility) surface can leads two common style of curve:\nSmile Surve (due to fat tail distributions):\n","permalink":"http://localhost:1313/posts/option-trading-and-black-scholes/","summary":"\u003cp\u003eWhat is Option Trading ?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA security giving the right to buy or sell an asset, subject to certain conditions, with a specified period of time.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eStrike Price 行权价； Premium 期权价；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEuropean Option: Exercisable only on the expiration date.\nAmerican Option: Can be exercised at any time before the expiration date.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://p.ipic.vip/phebaw.png\" alt=\"image-20250222143349581\"  /\u003e\n\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eWhen the stock price is much greater than theexercise price,\u003c/strong\u003e the option is almost sure to be exercised. The current value ofthe option will thus be approximately equal to the price of the stock minusthe price of a pure discount bond that matures on the same date as theoption, with a face value equal to the striking price of the option.\u003c/p\u003e","title":"Digest | Option Trading"},{"content":"Transaction Transaction is a series of queries\nIt\u0026rsquo;s the unit of operation\nNon-devisible, either all queries executed, either none\nImportant way to maintain consistency and data integrity\nBEGIN TRANSACTION SELECT * FROM A COMMIT; ROLLBACK; Atomicity The transaction is indivisible Rollback when failed The Atomicity is achived by Undo Log Undo log stores the reversve operation logic with every queries Undo log is stored in the different table space It will mainly record the value and operation If a ROLLBACK invoked, the data is able to be restored by undo-log Consistency Consistency refers to data consistency and read consistency\nData Consistency means the data can be cross valided by different logfic on different places. Read Consistency means no lag in reading data? Consistency is the goal, A, I, and D are the approaches.\nIsolation Isolation is the key feaures to ensure the concurrency while not affecting data consistency and integrety 4 scenarios that needs to be optimised by different level of isolations Read-Read: No affect Write-Write: Two transactions writing on the same field. Add Lock Read-Write: Read-write scenarios will results in a lot of issues if not setting the isolation level properly. It will lead: Dirty Read, Un-repeatable Read and Phantom read. Different lock in Read-read: By Lock mode:\nExclusive lock (X)\nOther transaction are not allowed any read/write operations on the locked row START TRANSACTION; UPDATE table_name SET column1 = \u0026#39;value\u0026#39; WHERE id = 1; -- X锁加在id=1的行上 UPDATE table_name SET column1 = \u0026#39;value\u0026#39; WHERE id = 1 FOR UPDATE; -- 显式上X锁加在id=1的行上 UPDATE table_name SET column1 = \u0026#39;1\u0026#39; WHERE id = \u0026#39;1\u0026#39; FOR UPDATE SELECT column1 FROM table_name where id = \u0026#39;2\u0026#39; FOR UPDATE SELECT ... FOR UPDATE：对特定记录加X锁。\nUPDATE / DELETE / INSERT：自动加X锁。\nLOCK TABLE ... IN EXCLUSIVE MODE：对整张表加X锁。\nRelease after commit or rollback Shared Lock （S）\nEnsure the read row is read-only\nSELECT column1, column2 FROM table_name WHERE condition FOR SHARE; SELECT column1 FROM table_name WHERE id = \u0026#39;a\u0026#39; LOCK IN SHARE MODE Release after commit or rollback\nIntend lock (IS or IX)\nIt is applied on a page level; This is for indicating a transaction is intends to set a S/X lock on individual row level, to prevent the potential conflicts For example: Transaction A, Row A has a S lock Table AA will be added with an IS lock automatically When Transaction B is going to add an X lock on Table AA before A is committed, it will block Update Lock (U)\nAvoid the dead lock when two transaction want to update the same target while the raw has added S lock by both of the transaction\nExample:\nBEGIN; SELECT * FROM orders WHERE id = 1 WITH (UPDLOCK); -- 加 U锁 -- 决定更新数据，U锁升级为 X锁 UPDATE orders SET status = \u0026#39;processed\u0026#39; WHERE id = 1; COMMIT; BEGIN; SELECT * FROM orders WHERE id = 1 WITH (UPDLOCK); -- 加 U锁，被阻塞直到事务A完成 -- 决定更新数据 UPDATE orders SET status = \u0026#39;canceled\u0026#39; WHERE id = 1; COMMIT; Dead Lock Example:\n事务A对某行加S锁。 事务B对同一行加S锁。 事务A尝试将S锁升级为X锁，但需要等待事务B释放S锁。 事务B也尝试将S锁升级为X锁，但需要等待事务A释放S锁. 结果：事务A和事务B相互等待，发生死锁。 Record Lock\nGap Lock\nNext Key Lock\nHow to optimise the concurrency in Read-Write Scenarios Different isolation level: Read uncommited: The in-flight transaction can read the uncommited change. Read commited: The in-flight transaction can read the commited change only .It avoids the dirty read Repeatable read: The in-flight transaction can only read the transaction that\u0026rsquo;s been commited before the current transaction. It avoids the dirty read and unrepeatable read. Serilizable Only one transaction is permitted at a moment. Read Committed and Repeated Read is achived by Multi-version Concurrency Control (MVCC) Three Important components of MVCC: Hidden Fields: Transaction ID and Roll back pointer The readview The Undo log chain By comparing the current transaction id and the trasnaction id in the undo log chain Durability The Durability is achievd by Redo Log\nEvery transaction will be write in Redo Log. Redo log stored in the ROM Transaction applied on the buffer pool buffer pool flashes the datafile on ROM regularly A complete process of executing a transaction Transaction Begin Lookingfor or Loading the data in the Buffer Pool Record the operations on Undo Log Update the Memory Data: Including Buffer Pool and Redo Log Buffer Write the Redo Log on disk drive Commit the transaction Record all operations of the transaction in BinLog The changed value on buffer pool will be flashed to disk regularly Index Why Do We Need an Index? Without an index, searching for a specific row in a table involves scanning all rows sequentially, resulting in a time complexity of O(n) for read operations. Indexing accelerates query performance by enabling faster lookups, particularly in large datasets. How data stored in DB Logically, they are stored as rows and columns in DB Hash Index What Is a Hash Index? A hash index is a data structure that accelerates query operations by creating a mapping between key values in one or more columns of a table and their corresponding storage locations.\nHow It Works: Hash Function Each key value is passed through a hash function, which transforms the key into a hash value. A good hash function ensures that inputs are distributed uniformly across the hash space, minimizing clustering and hash collisions. Bucket Mapping The number of buckets, mm, is determined, which represents storage divisions in memory. The specific bucket for a key is calculated as:Bucket Index=Hash Function(key)mod mBucket Index=Hash Function(key)modm Handling Hash Collisions Collision Definition: Two different keys may produce the same hash value, resulting in a collision. Collision Resolution Methods Chaining (Linked List): Multiple values mapped to the same bucket are stored in a linked list. Open Addressing: If a bucket is already occupied, an alternative bucket is located based on a probing sequence (e.g., linear probing or quadratic probing). Storage of Hash Index: The hash index is typically stored in RAM for fast access. To ensure data durability in the event of failure, Write-Ahead Logging (WAL) or other persistence mechanisms can be used. Pointer to Data Rows: The value in a hash index is a pointer or reference to the row in the table, allowing direct access to the data. Time Complexity of Hash Index Average Case: O(1)for lookups, insertions, and deletions, as hash functions provide direct access to buckets. Worst Case: O(n), which occurs when hash collisions lead to a single bucket storing many entries (e.g., all keys hashing to the same bucket). Why Use a Hash Index? Advantages: Efficient Query Performance Hash indices provide constant-time O(1)O(1) lookups for equality-based queries (= or IN). Low Memory Overhead Hash indices are compact and require less memory compared to tree-based indices like B-trees. Limitations: No Range Query Support Hash indices are unsuitable for range queries (e.g., \u0026lt;, \u0026gt;, BETWEEN) because hash functions do not preserve order. Random Distribution of Keys Hash functions distribute keys randomly across buckets, making ordered operations (like ORDER BY) impossible using the index. Collision Overhead Handling hash collisions adds complexity and may degrade performance in scenarios with poor hash function design or high data skew. Additions and Enhancements Durability: While you mentioned WAL for durability, it\u0026rsquo;s worth noting that hash indices are often rebuilt after a crash if stored only in memory, making them better suited for temporary tables or volatile workloads. Comparison to Other Index Types: Compared to B-tree indices: Hash indices are faster for equality queries. B-trees are more versatile, supporting range queries, order maintenance, and prefix matching. Common Use Cases: Hash indices are ideal for: Lookup tables with frequent equality queries. Key-value stores and in-memory databases (e.g., Redis). Indexing columns with unique or near-unique values. How to implement Hash Index CREATE TABLE test ( id INT, value VARCHAR(255), PRIMARY KEY (id), KEY(value) USING HASH ) ENGINE=Memory; B Tree Why do we need B-Tree We want to query the data in log time What is B-Tree It\u0026rsquo;s a balance tree: All the leaf nodes are on the same level Multi-branching: With a m-order B-tree, it has Maximum m child nodes, minimum m/2 child nodes Maximum m-1 keys in one node, minimum m/2 -1 leys in one node (except for the root node) Order: Every keys are sorted in a ascending order The value stored on each key is the pointer pointing to the corresponding row Insertion in B-Tree Starting from the root node, and navigating to the corresponding position on the leaf node. All keys in the node are sorted in the ascending order. If the number of keys is greater than m-1, split the node into two, and push the middle key as the father node. (anchestor node?) Deletion in B-Tree Starting from the root node, and navigating to the corresponding position. If the deletion target is the leaf node, delete it, If the number of nodes after deleetion is smaller than m/2-1, take the sbling node as the new seperator in the parent node, and take the original seperator into the target leaf node If the sbling node is also at the minumum nodes, then we can merge the target node, the separator and the sbling node together If the target node is non-leaf node, we have to find an alternative key as the seprator, this could be the largest key on the left-hand child node, or the smallest key of the righ-hand side child node I/O of B-Tree The B-Tree is stored in hard Drive\nEach time, it will read a single level of nodes into the RAM\nB+ Tree Difference from B-Tree:\nIn B-Tree, the values of all nodes contains to pointer pointing to the record In B-Tree, only the leaf node contains the pointer pointing to the record m order B-tree has maximum m-1 keys in a single mode m order B+ tree has maximum m keys in a single mode, each key on the non-leaf node is the maximum value of it\u0026rsquo;s childern node B+ Tree has an additional pointer starting at the leaf node. Making it easy to do sequantial search and range query ![image-20250112154345629](/Users/duanwenbo/Library/Application Support/typora-user-images/image-20250112154345629.png)\nClustered and non-clustered Index Note this is another dimention to describe index. The data srtrucuter is all B+ Tree by default. The major difference is either we put the real data or the pointer on the leaf node ","permalink":"http://localhost:1313/posts/transaction/","summary":"\u003ch3 id=\"transaction\"\u003eTransaction\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTransaction is a series of queries\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIt\u0026rsquo;s the unit of operation\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNon-devisible, either all queries executed, either none\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eImportant way to maintain consistency and \u003cem\u003edata integrity\u003c/em\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sql\" data-lang=\"sql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eBEGIN\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eTRANSACTION\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eSELECT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eFROM\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eCOMMIT\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eROLLBACK\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"atomicity\"\u003eAtomicity\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eThe transaction is indivisible\u003c/li\u003e\n\u003cli\u003eRollback when failed\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"the-atomicity-is-achived-by-undo-log\"\u003eThe Atomicity is achived by Undo Log\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eUndo log stores the reversve operation logic with every queries\u003c/li\u003e\n\u003cli\u003eUndo log is stored in the different table space\u003c/li\u003e\n\u003cli\u003eIt will mainly record the value and operation\u003c/li\u003e\n\u003cli\u003eIf a ROLLBACK invoked, the data is able to be restored by undo-log\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"consistency\"\u003eConsistency\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eConsistency refers to data consistency and read consistency\u003c/p\u003e","title":"Digest | SQL Quick Note 2"},{"content":" Pain is inevitable, suffering is Optional\n# 为什么想写小说？\n想要的东西往往心里早就有了答案。下定决心的时刻往往只是一个恰当的契机。\n为什么成为作家？ 大概就是在一个天气正好，风暖日丽的下午，在边喝啤酒，边看棒球。 当看到喜欢的球队久违的击中全垒打时，便做下决定：\n\u0026gt; 我还清晰地记得那晴朗的天空，刚刚恢复了绿色的草坪的触感，以及棒球发出的悦耳声响。在那一刻，有什么东西静静地从天空飘落下来，我明白无误地接受了它。\n# 为什么喜欢跑步？\n首先是合不合适，跑步起初是一不令人讨厌的运动，条件要求不高，也非竞技性。跑步支持他健康的生活，写作。\n但是，每天坚持跑步同意志的强弱，并没有太大的关联。他能坚持跑步二十年，恐怕还是应为跑步适合他的性情。喜欢的事儿自然可以坚持下去。\n无论何等争强好胜的人，不喜欢的事情终究做不到持之以恒；做到了，也对身体不利。\n# 如何坚持？\n练习感恩的能力。任怎么说长跑与性情多么相符，也总有偷懒，不想跑步的日子。这很正常，所有人都会有。\n\u0026gt; 但是，觉得“今天不想跑步”的时候，我常问题自己一个问题：“你大体作为一个小说家在生活，可以在喜欢的时间一个人待在家里工作，既不需早起晚归挤在满员电车里受罪，也不需出席无聊的会议。这不是很幸运的事儿么？与之相比，不就是在附近跑上一个小时么，有什么大不了的？”\n# 跑步带来的方法论\n如何写出伟大的小说？\n对于小说家，最重要的资质，无需赘言，当然是才华； 才华之外，是集中力。这是将自己拥有的有限的才能聚集，尔后倾注于最为需要之处的能力。 集中里之后，必须是耐力。 值得庆幸的是，后两者与才华不同，可以通过训练于后天获得。 \u0026gt; 才华横溢的作家可以下意识甚至无意识地这样进行工作。尤其是年轻人，*年轻，就意味着浑身充满自然的活力。*集中里和耐力，如果需要，它们会自己跑过来。\n不是那般富于才华、徘徊在一般水平上下的作家，只能从年轻时起努力培养膂力。他们通过训练来培养集中力，增进耐力，无奈地拿这些资质做才华的“代用品”。如此这般好歹地“苦撑”之时，也可能邂逅潜藏于自己内部的才华。手执铁锹，挥汗如雨，奋力在脚下挖着坑，竟然瞎猫撞着了死老鼠，挖到了沉睡在地下的神秘水脉，真是所谓的幸运。而追根溯源，恰恰是通过训练养成了足够的膂力，深挖坑穴才成为可能。到了晚年，才华之花方才怒放的作家，多多少少经过这样的历程。\n\u0026gt; 希冀长命百岁而跑步的人，大概不多。怀着“不能长命百岁不打紧，至少想在有生之年过得完美”这种心情跑步的人，只怕多得多。 同样是十年，与其稀里糊涂地活过，明确目的，生气勃勃地活着当然令人最为满意。\n# 享受过程，接纳自己，丢掉期待\n\u0026gt; 并不是有个人跑来找我，又劝我“你跑步吧”，我就沿着马路开始跑步。也没有什么人跑来找我，跟我说“你当小说家吧”，我就开始写小说。突然有一天，我出于喜欢开始写小说。又有一天，我出于喜欢开始在马路上跑步。不拘什么，按照喜欢的方式做喜欢的事，我就是这样生活的。纵然受到别人阻止，遭到恶意非难，我都不曾改变。这样一个人，又能向谁索求什么呢？\n我仰望天空。能看到一丝一毫的爱心么？不，看不到。只有太平洋上空悠然飘来浮去，无所事事的夏日云朵。云朵永远沉默无语。它们什么都不对我说。或许我不该仰望天空，应当将视线投去我的内部。我试着看向自己的内部，就如同窥视深深的井底。那里可以看到爱心么？不，看不到。看到的只有我的性格。我那个人的，顽固的，缺乏协调性的，每每任性妄为又常常怀疑自己的，哪怕遇到痛苦也想在其中发现可笑之处的性格。我拎着它，就像拎着一个古旧的旅行包，踱过了漫长的历程。我并不是因为喜欢才拎着它。与内容相比，它显得太沉重，外观也不起眼，还到处绽开了线。我只是没有别的东西可拎，无奈才拎着它彷徨徘徊。然而，我心中却对它怀有某种依依不舍的情感。\n","permalink":"http://localhost:1313/posts/what-i-talk-about-when-i-talk-about-running/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://p.ipic.vip/ek53t0.jpg\" alt=\"5982818\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003ePain is inevitable, suffering is Optional\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e# 为什么想写小说？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e想要的东西往往心里早就有了答案。下定决心的时刻往往只是一个恰当的契机。\u003c/p\u003e\n\u003cp\u003e为什么成为作家？ 大概就是在一个天气正好，风暖日丽的下午，在边喝啤酒，边看棒球。 当看到喜欢的球队久违的击中全垒打时，便做下决定：\u003c/p\u003e\n\u003cp\u003e\u0026gt; 我还清晰地记得那晴朗的天空，刚刚恢复了绿色的草坪的触感，以及棒球发出的悦耳声响。在那一刻，有什么东西静静地从天空飘落下来，我明白无误地接受了它。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e# 为什么喜欢跑步？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e首先是合不合适，跑步起初是一不令人讨厌的运动，条件要求不高，也非竞技性。跑步支持他健康的生活，写作。\u003c/p\u003e\n\u003cp\u003e但是，每天坚持跑步同意志的强弱，并没有太大的关联。他能坚持跑步二十年，恐怕还是应为跑步适合他的性情。喜欢的事儿自然可以坚持下去。\u003c/p\u003e\n\u003cp\u003e无论何等争强好胜的人，不喜欢的事情终究做不到持之以恒；做到了，也对身体不利。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e# 如何坚持？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e练习感恩的能力。任怎么说长跑与性情多么相符，也总有偷懒，不想跑步的日子。这很正常，所有人都会有。\u003c/p\u003e\n\u003cp\u003e\u0026gt; 但是，觉得“今天不想跑步”的时候，我常问题自己一个问题：“你大体作为一个小说家在生活，可以在喜欢的时间一个人待在家里工作，既不需早起晚归挤在满员电车里受罪，也不需出席无聊的会议。这不是很幸运的事儿么？与之相比，不就是在附近跑上一个小时么，有什么大不了的？”\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e# 跑步带来的方法论\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e如何写出伟大的小说？\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e对于小说家，最重要的资质，无需赘言，当然是才华；\u003c/li\u003e\n\u003cli\u003e才华之外，是集中力。\u003cstrong\u003e这是将自己拥有的有限的才能聚集，尔后倾注于最为需要之处的能力。\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e集中里之后，必须是耐力。\u003c/li\u003e\n\u003cli\u003e值得庆幸的是，后两者与才华不同，可以通过训练于后天获得。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026gt; 才华横溢的作家可以下意识甚至无意识地这样进行工作。尤其是年轻人，*年轻，就意味着浑身充满自然的活力。*集中里和耐力，如果需要，它们会自己跑过来。\u003c/p\u003e\n\u003cp\u003e不是那般富于才华、徘徊在一般水平上下的作家，只能从年轻时起努力培养膂力。他们通过训练来培养集中力，增进耐力，无奈地拿这些资质做才华的“代用品”。如此这般好歹地“苦撑”之时，也可能邂逅潜藏于自己内部的才华。手执铁锹，挥汗如雨，奋力在脚下挖着坑，竟然瞎猫撞着了死老鼠，挖到了沉睡在地下的神秘水脉，真是所谓的幸运。而追根溯源，恰恰是通过训练养成了足够的膂力，深挖坑穴才成为可能。到了晚年，才华之花方才怒放的作家，多多少少经过这样的历程。\u003c/p\u003e\n\u003cp\u003e\u0026gt; 希冀长命百岁而跑步的人，大概不多。怀着“不能长命百岁不打紧，至少想在有生之年过得完美”这种心情跑步的人，只怕多得多。 同样是十年，与其稀里糊涂地活过，明确目的，生气勃勃地活着当然令人最为满意。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e# 享受过程，接纳自己，丢掉期待\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u0026gt; 并不是有个人跑来找我，又劝我“你跑步吧”，我就沿着马路开始跑步。也没有什么人跑来找我，跟我说“你当小说家吧”，我就开始写小说。突然有一天，我出于喜欢开始写小说。又有一天，我出于喜欢开始在马路上跑步。不拘什么，按照喜欢的方式做喜欢的事，我就是这样生活的。纵然受到别人阻止，遭到恶意非难，我都不曾改变。这样一个人，又能向谁索求什么呢？\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e我仰望天空。能看到一丝一毫的爱心么？不，看不到。只有太平洋上空悠然飘来浮去，无所事事的夏日云朵。云朵永远沉默无语。它们什么都不对我说。或许我不该仰望天空，应当将视线投去我的内部。我试着看向自己的内部，就如同窥视深深的井底。那里可以看到爱心么？不，看不到。看到的只有我的性格。我那个人的，顽固的，缺乏协调性的，每每任性妄为又常常怀疑自己的，哪怕遇到痛苦也想在其中发现可笑之处的性格。我拎着它，就像拎着一个古旧的旅行包，踱过了漫长的历程。我并不是因为喜欢才拎着它。与内容相比，它显得太沉重，外观也不起眼，还到处绽开了线。我只是没有别的东西可拎，无奈才拎着它彷徨徘徊。然而，我心中却对它怀有某种依依不舍的情感。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Digest | 当我谈跑步时，我在谈些什么?"},{"content":"公司同事写了一本介绍金融市场与衍生品交易的书籍，面向所有非专业岗位的从业者与爱好者。于情于理于职业发展，我都应该读一遍。开此一贴，用作记录。\nSynthetic Assets Synthetic assets surround us in our daily lives. Look around you. The number 18 token that the cloakroom girl gave you in exchange for your coat? That is a synthetic asset. Its intrinsic value is nil. It is simply a small plastic disc, too large even to insert in the anti-theft system of your supermarket’s trolley. Instead, its value is as a sign. Only imagine the drama that would accompany its loss: a brand new coat! The cloakroom girl owns the other half of the key, an identical token, with the same number 18 emblazoned in gold. She also understands the convention. The person who offers her the matching token will be handed the corresponding coat. No further explanation is required. While a small tip might change hands, this is far from compulsory. Such an example might sound trivial. An unintentional exchange cannot be ruled out if the girl has a moment of absence. In general, however, the process leaves little room for confusion. On the other hand, when synthetic assets are meant to represent classes of objects, some of which can be abstract, things can become a little more confusing (Illustration 1)\n什么是合成资产？以在剧院寄存外套的小硬币为例，你把衣服交给前台的女孩，换来一个标记为18的塑料硬币，这是一个塑料片，实际价值约为0，甚至放不进tesco的手推车里。可能只有剧院会承担它带来的损失 - 一件全新的外套。女孩拥有钥匙的另一半，一个同样标记为18，但是金色装饰的硬币。她懂得如何转换 - 当女孩收到的硬币与自己手上的硬币匹配时，她便会把对应的外套取出来，无需多余的解释。或许有时会有一些小费，但这完全不是硬性要求。上述的流程可能听着琐碎，但是如果女孩不在场，我们不能排除一些无意错误交换发生的可能性。但一般来说，这个过程几乎不会造成混淆。但另一方面，当合成资产代表的事物越来越抽象时，事情可能会变的混乱起来。\n“金融是解决和构建关于金钱，时间和价值的方法” - Goetzman\n合成资产为操作其他金融资产提供了便利。原语言(meta-language)是描述一个语言结构时运用的一组专用符号。代数符号就是算数的原语言。0是数字里的原符号，现在的内容聚合也是新闻报纸的原内容，而合成资产是其他金融资产的原资产。\nThe word is not the thing, and the map is not the territory\n**合成资产必须有对应的，完全存在的标的。**而这是现在正在被越来越多的人忽视的。回到硬币的例子，当我拥有硬币时，我可能失去了我实际拥有一件外套的直观感觉，我可能会很轻易的丢掉它并且意识不到后果的严重 - 就像2008年的次贷危机那样。投资基金，提单， ETF，金融衍生品，金融基准，证券，Grain Receipt，电子黄金认股权证，自愿碳排放额度等都是合成资产，但他们代表的是实物商品、房地产、金融策略、抵押贷款、碳排放等等的其他金融资产。\nTwo Main Risk Management Frameworks Risk Pooling - 风险共担\n以保险为代表，通过对历史数据的量化精算来建立一个多样化的风险组合，分散风险。\n保险合同是对相应损失进行支付\nRisk Clearing - 风险清算\n以市场金融为代表，通过建立交易网络，使参与者方便的进行风险抵消交易。 金融衍生品合同根据客观的预定基准进行支付 The inability of counterparties to control the outcome of a financial transaction is key to the soundness of the financial structure\n交易对手无法控制金融交易的结果是金融结构稳健性的关键。 作为对比：\n保险: 可保利益原则：监管者规定了投保人的风险敞口，以避免投保人违规影响被保意外的结果 金融市场： 交易对手方不必证明风险敞口的合理性才能签订协议。 交易对手方通常没有机会控制意外事件的结果 (当然也有意外，但这与衍生品机制无关，更多的是市场的普遍问题，青山控股镍期货squeeze short事件作为代表)\nDematerialisation: A lower level of market economy: Shops, door-to-door salesmen\nA higher level: fairs and exchange\n金融市场与不同的衍生品极大增强了金融资产的流动性，实现资产的去物质化（Dematerialisation) The pyrimid of finacial abstraction: 流动性的不同层级 现金，实物资产\n已分配的资产（投资者有持有权）：电子仓单、单一资产实物ETF，分配给投资者的实物黄金\n未分配的资产（由银行持有，投资者对资产有债权）、公司信贷和债券。\n实物资产为基础的指数ETF和各种投资基金\n各种金融衍生品，如期货合约和信用违约互换（CDS）\n","permalink":"http://localhost:1313/posts/finacial-metaverse---introduction/","summary":"\u003cp\u003e公司同事写了一本介绍金融市场与衍生品交易的书籍，面向所有非专业岗位的从业者与爱好者。于情于理于职业发展，我都应该读一遍。开此一贴，用作记录。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://p.ipic.vip/mbw1gp.jpg\" alt=\"61D9cyRNmiL.AC_UF894,1000_QL80\"  /\u003e\n\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"synthetic-assets\"\u003eSynthetic Assets\u003c/h3\u003e\n\u003cp\u003eSynthetic assets surround us in our daily lives. Look around you. The number 18 token that the cloakroom girl gave you in exchange for your coat? That is a synthetic asset. Its intrinsic value is nil. It is simply a small plastic disc, too large even to insert in the anti-theft system of your supermarket’s trolley. Instead, its value is as a sign. Only imagine the drama that would accompany its loss: a brand new coat! The cloakroom girl owns the other half of the key, an identical token, with the same number 18 emblazoned in gold. She also understands the convention. The person who offers her the matching token will be handed the corresponding coat. No further explanation is required. While a small tip might change hands, this is far from compulsory. Such an example might sound trivial. An unintentional exchange cannot be ruled out if the girl has a moment of absence. In general, however, the process leaves little room for confusion. On the other hand, when synthetic assets are meant to represent classes of objects, some of which can be abstract, things can become a little more confusing (Illustration 1)\u003c/p\u003e","title":"Digest | Finacial metaverse"},{"content":" 综上所述，可知一切勾结帝国主义的军阀、官僚、买办阶级、大地主阶级以及附属于他们的一部分反动知识界，是我们的敌人。工业无产阶级是我们革命的领导力量。一切半无产阶级、小资产阶级，是我们最接近的朋友。那动摇不定的中产阶级，其右翼可能是我们的敌人，其左翼可能是我们的朋友——但我们要时常提防他们，不要让他们扰乱了我们的阵线。\n地主阶级，买办阶级 帝国主义，国际资产阶级的附庸。代表中国最落后与最反 What-I-Talk-About-When-I-Talk-About-Running.md 动的生产关系。\n中产阶级 民族资产阶级，对中国革命具有矛盾的态度。举起左手打倒帝国主义，举起右手打倒共产党\n小资产阶级，小知识阶级\n自耕农和手工业主所经营的，都是小生产的经济。\n右派\n第一部分是有余钱剩米的，即用其体力或脑力劳动所得。他们的经济地位和中产阶级颇接近，故对于中产阶级的宣传颇相信，对于革命取怀疑的态度。\n大部分属于中派\n受到帝国主义，军阀，地主阶级的剥削，想发财而不得\n小资产阶级左翼\n这一部分人好些大概原先是所谓殷实人家，渐渐变得仅仅可以保住，渐渐变得生活下降了。\n这种人在精神上感觉的痛苦很大，因为他们有一个从前和现在相反的比较。这种人在革命运动中颇要紧，是一个数量不小的群众，是小资产阶级的左翼。\n半无产阶级 贫农 小手工业者\n青黄不接，吃着不够。对于革命宣传极易接受。其需要一个变更现状的革命。\n无产阶级 工业无产阶级。\n其很大一部分数量是在外国资产阶级的奴役下。虽然数量不多，但代表中国最进步的阶级，做了革命的领导力量。他们所以能如此，第一个原因是集中。无论哪种人都不如他们的集中。第二个原因是经济地位低下。他们失了生产手段，剩下两手，绝了发财的望，又受着帝国主义、军阀、资产阶级的极残酷的待遇。\n农村无产阶级\n所谓农村无产阶级，是指长工、月工、零工等雇农而言。此种人在乡村中是最感困难者，在农民运动中和贫农处于同一紧要的地位。\n","permalink":"http://localhost:1313/posts/%E6%AF%9B%E9%80%89%E5%8D%B7%E4%B8%80/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://p.ipic.vip/fyn4iz.jpg\" alt=\"images\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e综上所述，可知一切勾结帝国主义的军阀、官僚、买办阶级、大地主阶级以及附属于他们的一部分反动知识界，是我们的敌人。工业无产阶级是我们革命的领导力量。一切半无产阶级、小资产阶级，是我们最接近的朋友。那动摇不定的中产阶级，其右翼可能是我们的敌人，其左翼可能是我们的朋友——但我们要时常提防他们，不要让他们扰乱了我们的阵线。\u003c/code\u003e\u003c/p\u003e\n\u003ch3 id=\"地主阶级买办阶级\"\u003e地主阶级，买办阶级\u003c/h3\u003e\n\u003cp\u003e帝国主义，国际资产阶级的附庸。代表中国最落后与最反 \u003ca href=\"What-I-Talk-About-When-I-Talk-About-Running.md\"\u003eWhat-I-Talk-About-When-I-Talk-About-Running.md\u003c/a\u003e 动的生产关系。\u003c/p\u003e\n\u003ch3 id=\"中产阶级\"\u003e中产阶级\u003c/h3\u003e\n\u003cp\u003e民族资产阶级，对中国革命具有矛盾的态度。举起左手打倒帝国主义，举起右手打倒共产党\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e小资产阶级，小知识阶级\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e自耕农和手工业主所经营的，都是小生产的经济。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e右派\u003c/p\u003e\n\u003cp\u003e第一部分是有余钱剩米的，即用其体力或脑力劳动所得。他们的经济地位和中产阶级颇接近，故对于中产阶级的宣传颇相信，对于革命取怀疑的态度。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e大部分属于中派\u003c/p\u003e\n\u003cp\u003e受到帝国主义，军阀，地主阶级的剥削，想发财而不得\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e小资产阶级左翼\u003c/p\u003e\n\u003cp\u003e这一部分人好些大概原先是所谓殷实人家，渐渐变得仅仅可以保住，渐渐变得生活下降了。\u003c/p\u003e\n\u003cp\u003e这种人在精神上感觉的痛苦很大，因为他们有一个从前和现在相反的比较。这种人在革命运动中颇要紧，是一个数量不小的群众，是小资产阶级的左翼。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"半无产阶级\"\u003e半无产阶级\u003c/h3\u003e\n\u003cp\u003e贫农 小手工业者\u003c/p\u003e\n\u003cp\u003e青黄不接，吃着不够。对于革命宣传极易接受。其需要一个变更现状的革命。\u003c/p\u003e\n\u003ch3 id=\"无产阶级\"\u003e无产阶级\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e工业无产阶级。\u003c/p\u003e\n\u003cp\u003e其很大一部分数量是在外国资产阶级的奴役下。虽然数量不多，但代表中国最进步的阶级，做了革命的领导力量。他们所以能如此，第一个原因是集中。无论哪种人都不如他们的集中。第二个原因是经济地位低下。他们失了生产手段，剩下两手，绝了发财的望，又受着帝国主义、军阀、资产阶级的极残酷的待遇。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e农村无产阶级\u003c/p\u003e\n\u003cp\u003e所谓农村无产阶级，是指长工、月工、零工等雇农而言。此种人在乡村中是最感困难者，在农民运动中和贫农处于同一紧要的地位。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"Digest | 谁是我们的朋友，谁是我们的敌人？"},{"content":"$$ C(S_t,t) = N(d_+) S_t - N(d_{-})Ke^{-r(T-t)} $$ Where N is the c.d.f of the normal distribution.\nB.S. formula services as an accurate mathmatical model to price the option, and enbale the people to hedge the risk against almost any underlying assets.\nThe Greeks for Black–Scholes are given in closed form below. They can be obtained by differentiation of the Black–Scholes formula.\nGreat Introduction:\nhttps://www.youtube.com/watch?v=A5w-dEgIU1M\nTo be continued\u0026hellip;\n","permalink":"http://localhost:1313/posts/black-scholes-formula/","summary":"\u003cp\u003e$$\nC(S_t,t) = N(d_+) S_t - N(d_{-})Ke^{-r(T-t)}\n$$\nWhere N is the c.d.f of the normal distribution.\u003c/p\u003e\n\u003cp\u003eB.S. formula services as an accurate mathmatical model to price the option, and enbale the people to hedge the risk against almost any underlying assets.\u003c/p\u003e\n\u003cp\u003eThe Greeks for Black–Scholes are given in closed form below. They can be obtained by differentiation of the Black–Scholes formula.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://p.ipic.vip/00e75e.png\" alt=\"Greek Letters for Market Risk\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eGreat Introduction:\u003c/p\u003e","title":"Note | Black-Scholes Formula"},{"content":"期货合约的定价机制 - 以LME铜为例 Background 大宗商品市场 大宗商品主要交易场所 CME：芝加哥商品交易所 LEM：伦敦金属交易所 ICE 大宗商品交易目的： 国际贸易 对冲风险 投机与投资 市场分类： 现金市场 衍生品市场： 期货 Future （场内交易） 远期 Forward （场外交易 OTC） 掉期 Swaps 期权 Options LME 铜的价格发现 LME参考价格 伦敦金属交易所铜的官方价格每日根据第二天早盘收盘时（伦敦时间 12:30-12:35，伦敦金属交易所公开喊价交易大厅）的买入价和卖出价确定。伦敦金属交易所官方结算价也是在场内确定的，是铜的现金卖方价格，广泛应用于世界各地的实物铜合约。这意味着它代表了任何经批准的伦敦金属交易所铜品牌的价格，这些铜可在两个工作日内交付于伦敦金属交易所全球仓库网络的任何地点。价格确定后，伦敦金属交易所会记录、分发和公布价格给世界各地的供应商，供应商再将数据传播给整个价值链上的行业用户。 交易所视频 -\u0026gt; https://www.youtube.com/watch?v=Mic1Q0oVfgM\u0026amp;t=4s 溢价 (Premium) 与折扣 (discount) LME参考价格不一定是最终合约价格。公司可以从这些价格发现组织和机制提供的更高透明度中受益。因此，公司可以更好地集中精力协商基础金属和其特定产品之间的溢价或折扣价值。这些溢价或折扣可能基于多种因素，其中包括最常提到的一些因素：地理位置、材料等级、杂质和交货条款。 Future Future is a contract that is defined and traded in the exchange. The product is obligation to buy/sell a standard quantity on a set future date, at a fixed price. Long / Short Position Futrue contract are traded at future exchanges. The buyer of a future contract is said to be the long (多头) position holder, and the seller is said to be the short (空头) position holder. Physical delivery / Cash settlement Cash settlement is made based on the underlying reference rate. The parties settle by paying/receiving the loss/gain related to contract in cash when contract expires. Explain concepts with Example I\u0026rsquo;m growing Potatos at Diddly Squat Farm\nFuture Contract:\nA standarlised legal agreement to buy or sell a financial asset ata predetermined price at a specified time in the future. I don\u0026rsquo;t know the market price in the coming year. Therefore, I want to set 100t potatos at price 100$/t in the next year, on 1st May 2025, to give me a garauntee profit. Future exchange:\nFutrue contract are traded at future exchanges. The buyer of a future contract is said to be the long position holder, and the seller is said to be the short position holder. ","permalink":"http://localhost:1313/posts/%E6%9C%9F%E8%B4%A7%E5%90%88%E7%BA%A6%E7%9A%84%E5%AE%9A%E4%BB%B7%E6%9C%BA%E5%88%B6---%E4%BB%A5lme%E9%93%9C%E4%B8%BA%E4%BE%8B/","summary":"\u003ch1 id=\"期货合约的定价机制---以lme铜为例\"\u003e期货合约的定价机制 - 以LME铜为例\u003c/h1\u003e\n\u003ch3 id=\"background\"\u003eBackground\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e大宗商品市场\n\u003cul\u003e\n\u003cli\u003e大宗商品主要交易场所\n\u003cul\u003e\n\u003cli\u003eCME：芝加哥商品交易所\u003c/li\u003e\n\u003cli\u003eLEM：伦敦金属交易所\u003c/li\u003e\n\u003cli\u003eICE\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e大宗商品交易目的：\n\u003cul\u003e\n\u003cli\u003e国际\u003cstrong\u003e贸易\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e对冲\u003c/strong\u003e风险\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e投机\u003c/strong\u003e与投资\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e市场分类：\n\u003cul\u003e\n\u003cli\u003e现金市场\u003c/li\u003e\n\u003cli\u003e衍生品市场：\n\u003cul\u003e\n\u003cli\u003e期货 Future （场内交易）\u003c/li\u003e\n\u003cli\u003e远期 Forward  （场外交易 OTC）\u003c/li\u003e\n\u003cli\u003e掉期 Swaps\u003c/li\u003e\n\u003cli\u003e期权 Options\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"lme-铜的价格发现\"\u003eLME 铜的价格发现\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eLME参考价格\n\u003cul\u003e\n\u003cli\u003e伦敦金属交易所铜的官方价格每日根据第二天早盘收盘时（伦敦时间 12:30-12:35，伦敦金属交易所公开喊价交易大厅）的买入价和卖出价确定。\u003c!-- raw HTML omitted --\u003e\u003cstrong\u003e伦敦金属交易所官方结算价也是在场内确定的，是铜的现金卖方价格，广泛应用于世界各地的实物铜合约。\u003c/strong\u003e\u003c!-- raw HTML omitted --\u003e这意味着它代表了任何经批准的伦敦金属交易所铜品牌的价格，这些铜可在两个工作日内交付于伦敦金属交易所全球仓库网络的任何地点。价格确定后，伦敦金属交易所会记录、分发和公布价格给世界各地的供应商，供应商再将数据传播给整个价值链上的行业用户。\u003c/li\u003e\n\u003cli\u003e交易所视频 -\u0026gt; \u003ca href=\"https://www.youtube.com/watch?v=Mic1Q0oVfgM\u0026amp;t=4s\"\u003ehttps://www.youtube.com/watch?v=Mic1Q0oVfgM\u0026amp;t=4s\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e溢价 (Premium) 与折扣 (discount)\n\u003cul\u003e\n\u003cli\u003eLME参考价格不一定是最终合约价格。公司可以从这些价格发现组织和机制提供的更高透明度中受益。因此，公司可以更好地集中精力协商基础金属和其特定产品之间的溢价或折扣价值。\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003e这些溢价或折扣可能基于多种因素，其中包括最常提到的一些因素：地理位置、材料等级、杂质和交货条款。\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"future\"\u003eFuture\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eFuture is a contract that is defined and traded in the exchange. The product is \u003cstrong\u003eobligation to buy/sell a standard quantity on a set future date, at a fixed price\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"long--short-position\"\u003eLong / Short Position\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eFutrue contract are traded at future exchanges. The buyer of a future contract is said to be the \u003cstrong\u003elong\u003c/strong\u003e (多头) position holder, and the seller is said to be the \u003cstrong\u003eshort\u003c/strong\u003e (空头) position holder.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"physical-delivery--cash-settlement\"\u003ePhysical delivery / Cash settlement\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCash settlement is made based on the underlying reference rate. The parties settle by paying/receiving the loss/gain related to contract in cash when contract expires.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"explain-concepts-with-example\"\u003eExplain concepts with Example\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eI\u0026rsquo;m growing Potatos at Diddly Squat Farm\u003c/em\u003e\u003c/p\u003e","title":"Note | 期货合约的定价机制 - 以LME铜为例"},{"content":"2024年8月18日，在Bristol Art Museun 和Pipa一起端详到一幅18世纪布里斯托城市地图。画笔精细，标注翔实。跟随地图序号的小标指引，仿佛能穿越历史。\n然而，从1到29的地图序号标注中，唯独序号7: Padmoor\u0026rsquo;s nen Crane 难觅踪影。上下扫描，来回切换，左右横跳，辗转反侧，只留下一个问题：7号建筑去哪儿了？？ 在原画中找不到7号建筑后，遂花一晚时间，开始考古，收获一些fun facts：\n结论1: Padmoors nen Crane 在地图中并未实际标出 经过反复观察，标号7并未出现在原作地图中。在英国政府艺术收藏网站 中，检索到两幅高清彩色版本地图，除开原图[《The South East Prospect of the City of Bristol》][The South East Prospect of the City of Bristol] 外，还有一幅对方视角的地图 《The North West Prospect of the City of Bristol》：\n序号7位于两座地标性建筑：redcliff church (10号) 与 The college (6号) 中间，因此很容易在两幅地图中定位对比，然而，序号7建筑在两幅相对视角的图中均未标注提及。这也让寻找Padmoor\u0026rsquo;s nen Crane 变得更加有趣。\n结论2: Padmoor\u0026rsquo;s nen Crane 应理解为“Padmoor的一座起重机” John Padmore，18世纪来自布里斯托的工程师。在1742年出版的《A Tour thro\u0026rsquo; the whole island of Great Britain》[1] 中，Padmore 将自己描述为“Millwright and shareholder in the Bristol Brass Company”。根据Tony Coverdale的介绍，Padmore的工程成就众多，根据其中就包括两座起重机 (Crane):\nThe Dolemeads Wharf Crane (1729 建成) The great Crane, Bristol (1733 建成) 原地图完成于1734年，仅凭建成时间很难判断地图中所指的 Padmoor\u0026rsquo;s nen Crane 为哪一座。所幸，第一座起重机在另一幅地图 《The South East Prospect of the City of Bath》中有被提及。可以确定，The Dolemeads Wharf 位于巴斯市，因此，由Padmore设计建造，并且位于Bristol 仅剩下一个选项 - The Great Crane, Bristol.\n关于 The Great Crane, Bristol，在多处文献中有提及。在《布里斯托尔工业考古学会》1975年期刊卷8中，\n其外形被描述为\nThe Bristol crane is of the house type, in its way a large enclosed version of the Combe Down cranes, and was raised up on 14 columns which are variously described as being of timber and of cast iron.\n此次之外，John Evans 在《History of Bristol》中，对 Greate Crane的外型也做了详细描绘:\n结论3: 建筑7-Padmoor\u0026rsquo;s nen Crane 位于Mud Dock 根据《History of Bristol》记载，这座起重机位于Mud Dock。 翻开布里斯托市政厅的1828年地图存档，能发现Mud Dock紧邻 Queen Square。\n将之与原地图东南视角作比较，很容易能找到24号地点正是Queen Squre。在地图中，Queen Squre紧邻The College与河岸。在河岸旁边，有一座围绕着许多帆船的长长房子。尽管画的不如 John Evans的细致，这座房子的方位与外型特征与不同出处的文献记载高度吻合。\n因此，我们断定，在西北视角地图中我们寻找的 PadMoor nen Crane位于Avon River的Mud Dock上，是一座外形类似House的长条形，矗立在码头边的建筑。由于西北视角下 Queen Squre周围的建筑被遮挡，作者在此时并未画出建筑7。相反，在东南视角地图中，建筑7清晰可见，但遗憾的是作者并未标注出来。\n不知道画图的人是疏忽还是玩笑，也不知道在博物馆里行走的人流中是否有人对这1/29的标记产生疑惑，但可以肯定的是，在这幅地图创作完成的290年后，有两个年轻人生命中的两天，对它充满了好奇。\n","permalink":"http://localhost:1313/posts/2024-08-19-where-does-7-go-/","summary":"\u003cp\u003e2024年8月18日，在Bristol Art Museun 和Pipa一起端详到一幅18世纪布里斯托城市地图。画笔精细，标注翔实。跟随地图序号的小标指引，仿佛能穿越历史。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://p.ipic.vip/bmvuzf.jpg\" alt=\"The south east prospect of city of Bristol\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e然而，从1到29的地图序号标注中，唯独序号7: \u003cem\u003ePadmoor\u0026rsquo;s nen Crane\u003c/em\u003e 难觅踪影。上下扫描，来回切换，左右横跳，辗转反侧，只留下一个问题：7号建筑去哪儿了？？ 在原画中找不到7号建筑后，遂花一晚时间，开始考古，收获一些fun facts：\u003c/p\u003e\n\u003ch3 id=\"结论1-padmoors-nen-crane-在地图中并未实际标出\"\u003e结论1: Padmoors nen Crane 在地图中并未实际标出\u003c/h3\u003e\n\u003cp\u003e经过反复观察，标号7并未出现在原作地图中。\u003ca href=\"https://artcollection.culture.gov.uk\"\u003e在英国政府艺术收藏网站\u003c/a\u003e 中，检索到两幅高清彩色版本地图，除开原图[《The South East Prospect of the City of Bristol》][The South East Prospect of the City of Bristol] 外，还有一幅对方视角的地图 \u003ca href=\"https://artcollection.culture.gov.uk/artwork/9633/\"\u003e《The North West Prospect of the City of Bristol》\u003c/a\u003e：\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003e序号7位于两座地标性建筑：redcliff church (10号) 与  The college (6号) 中间，因此很容易在两幅地图中定位对比，然而，序号7建筑在两幅相对视角的图中均未标注提及。这也让寻找Padmoor\u0026rsquo;s nen Crane 变得更加有趣。\u003c/p\u003e","title":"Daily | Where does 7 go ??"},{"content":"今年过的尤其快速。一晃眼，年关又至。我相信这样的记录珍贵，但预料之外的，是由体验归档成回忆的过程，随着年岁增长，愈发快速。\n365天前，我敲下了第一篇回忆留给2022。一轮春夏秋冬，酸甜苦辣皆有，承前往后，有连续的思绪，有难耐的孤独，对挑战释怀，与自己和解。于不知不觉间，我的社会角色已经转变。\n此刻再将时间线拉长，回首，回味，真是有趣。\n21岁是我对未来幻想的开始，照王小波的讲法：\n那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。\n无尽遐想过后，第一次对未知的焦虑也随之带来。我于是思考，阅读，得出的第一个答案是奋斗。于是在备忘录里写道\n流年似水，苦短人生。缓解焦虑的处方千千万，但最好的处方，大概还是奋斗和拼搏。\n22岁，我在汉诺威码头的公寓里，开始思考未来我该做什么：\n庆幸的是，在同年的夏天，我就得到了一份与之相关的实习工作。然而伴随而来的，是无力感，第一次向目标挑战的挫败感，我于是写道：\n2021年的进度已经走完一大半，状态栏上8月底的日历告诉我，我很快会在23岁的年头了。我不敢面对，因为我的生活一事无成，枯燥乏味。我害怕浪费所谓的韶华青春，所以我用埋头的工作，对抗未知的焦虑。但是昨晚的熬夜让我有一种无力感，无力面对新的挑战，即使自己看起来全力以赴，也不过是九牛一毛罢了。我想从这种怪圈里面跳脱出来。\n我想从这种怪圈里面跳脱出来，我想拥有一个充实高效的生活，我想拥有一个晴朗的夏天。\n23岁，是向社会过渡的一年，是在来到英国4年后的第一次外向探索。我在夏天搬到了沃特福德，继续我对未来的体验。我很感激这段经历，它满足了我对工作的期待，对生活的实践。我写道：\n6月底，在没有那么强烈的告别情绪下，我就匆匆搬到了沃特福德。坦率说，我是喜欢这种漂泊和新环境的，他给人一种新希望与新开始。脱离布里斯托的校园，陌生的环境，有无限的可能。当第一次走进公司，拿完设备，坐在工位上时，我第一次如此强烈的感觉到自己社会角色的转变。\n在沃特福德的夏天是独特难忘的，我依然一个人，但并不感到孤独。我开始像模像样的享受上班的生活，每天5点半后，太阳依然耀眼，我会躲进清凉安静的小镇火车里，看着窗外律动的草丛发呆。\n对于24岁的2023年，一切都仿佛暂停重置了。\n今年，在帝国理工的学业与找工作的压力并行，充满挑战。忍受孤独，拥抱学术，思考，争取。9月前的每一步，都仿佛是一记锤打。滑动今年的相册，回忆林林总总。此刻还难忘的瞬间，约莫有三。\n我本以为自己是一个麻木的人，面对压力还算自如。但是3月，第一次顶不住压力的哭泣。尽管早已知道帝国理工的学业将会加重，但我那时显然没处理好陡然增加的压力。在学业与找工作的拉扯中，我的一项课程作业将会迟交。于是在距离提交作业的5天前，我提出了延迟提交的申请。我原本以为这是一次不完美但正确的流程，但未曾想到，迎接我的，是系主任的面询，是领到supervisor面前的询问，是领着去faculty office的对话。我仿佛什么都做了，但又什么都错了。当其他老师发出关心但他说出 He doesn\u0026rsquo;t care 时，那一刻，无力和挫败感到达极点。我忍住情绪，直到倚靠在厕所隔间的门背。我不敢大声抽泣，只是把鼻涕擤干，待到没人时走出。\n其二要数找工时期的迷茫了。这是一个干燥乏闷的过程，是把幻想拖回现实的过程。曾经想象的一切是那么触手可及，但又无可奈何。林林总总的准备，失而复得的面试，几刻钟和面试官的交流，几段随机的文字，就决定了以后。像是一场没有目的地的旅行，已经出发，能做的只有尽力，能解释的只有缘份。最终阴差阳错，半只脚跨进银行，但我真的热爱它吗？如果不是，我该如何取舍？\n其三要属工作之后对自己的思考。这种思绪在上班之后尤为明显。坦率的讲，我现在在一个尴尬的位置与年岁。向往yolo，但不敢轻易改变；想要轰轰烈烈，但又囹囵两点一线。其间见到一些有趣的人，共同的特点是都坚信且贯彻自己的未来目标。这让我意识到我应当做些什么。\n当然，剩下的时间快乐占据大多数 :)\n","permalink":"http://localhost:1313/posts/%E5%86%99%E5%9C%A82023%E5%B9%B4%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%A4%A9/","summary":"\u003cp\u003e今年过的尤其快速。一晃眼，年关又至。我相信这样的记录珍贵，但预料之外的，是由体验归档成回忆的过程，随着年岁增长，愈发快速。\u003c/p\u003e\n\u003cp\u003e365天前，我敲下了第一篇回忆留给2022。一轮春夏秋冬，酸甜苦辣皆有，承前往后，有连续的思绪，有难耐的孤独，对挑战释怀，与自己和解。于不知不觉间，我的社会角色已经转变。\u003c/p\u003e\n\u003cp\u003e此刻再将时间线拉长，回首，回味，真是有趣。\u003c/p\u003e\n\u003cp\u003e21岁是我对未来幻想的开始，照王小波的讲法：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e无尽遐想过后，第一次对未知的焦虑也随之带来。我于是思考，阅读，得出的第一个答案是奋斗。于是在备忘录里写道\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e流年似水，苦短人生。缓解焦虑的处方千千万，但最好的处方，大概还是奋斗和拼搏。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e22岁，我在汉诺威码头的公寓里，开始思考未来我该做什么：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://p.ipic.vip/fnwqgg.png\" alt=\"01\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e庆幸的是，在同年的夏天，我就得到了一份与之相关的实习工作。然而伴随而来的，是无力感，第一次向目标挑战的挫败感，我于是写道：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e2021年的进度已经走完一大半，状态栏上8月底的日历告诉我，我很快会在23岁的年头了。我不敢面对，因为我的生活一事无成，枯燥乏味。我害怕浪费所谓的韶华青春，所以我用埋头的工作，对抗未知的焦虑。但是昨晚的熬夜让我有一种无力感，无力面对新的挑战，即使自己看起来全力以赴，也不过是九牛一毛罢了。我想从这种怪圈里面跳脱出来。\u003c/p\u003e\n\u003cp\u003e我想从这种怪圈里面跳脱出来，我想拥有一个充实高效的生活，我想拥有一个晴朗的夏天。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e23岁，是向社会过渡的一年，是在来到英国4年后的第一次外向探索。我在夏天搬到了沃特福德，继续我对未来的体验。我很感激这段经历，它满足了我对工作的期待，对生活的实践。我写道：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e6月底，在没有那么强烈的告别情绪下，我就匆匆搬到了沃特福德。坦率说，我是喜欢这种漂泊和新环境的，他给人一种新希望与新开始。脱离布里斯托的校园，陌生的环境，有无限的可能。当第一次走进公司，拿完设备，坐在工位上时，我第一次如此强烈的感觉到自己社会角色的转变。\u003c/p\u003e\n\u003cp\u003e在沃特福德的夏天是独特难忘的，我依然一个人，但并不感到孤独。我开始像模像样的享受上班的生活，每天5点半后，太阳依然耀眼，我会躲进清凉安静的小镇火车里，看着窗外律动的草丛发呆。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e对于24岁的2023年，一切都仿佛暂停重置了。\u003c/p\u003e\n\u003cp\u003e今年，在帝国理工的学业与找工作的压力并行，充满挑战。忍受孤独，拥抱学术，思考，争取。9月前的每一步，都仿佛是一记锤打。滑动今年的相册，回忆林林总总。此刻还难忘的瞬间，约莫有三。\u003c/p\u003e\n\u003cp\u003e我本以为自己是一个麻木的人，面对压力还算自如。但是3月，第一次顶不住压力的哭泣。尽管早已知道帝国理工的学业将会加重，但我那时显然没处理好陡然增加的压力。在学业与找工作的拉扯中，我的一项课程作业将会迟交。于是在距离提交作业的5天前，我提出了延迟提交的申请。我原本以为这是一次不完美但正确的流程，但未曾想到，迎接我的，是系主任的面询，是领到supervisor面前的询问，是领着去faculty office的对话。我仿佛什么都做了，但又什么都错了。当其他老师发出关心但他说出 He doesn\u0026rsquo;t care 时，那一刻，无力和挫败感到达极点。我忍住情绪，直到倚靠在厕所隔间的门背。我不敢大声抽泣，只是把鼻涕擤干，待到没人时走出。\u003c/p\u003e\n\u003cp\u003e其二要数找工时期的迷茫了。这是一个干燥乏闷的过程，是把幻想拖回现实的过程。曾经想象的一切是那么触手可及，但又无可奈何。林林总总的准备，失而复得的面试，几刻钟和面试官的交流，几段随机的文字，就决定了以后。像是一场没有目的地的旅行，已经出发，能做的只有尽力，能解释的只有缘份。最终阴差阳错，半只脚跨进银行，但我真的热爱它吗？如果不是，我该如何取舍？\u003c/p\u003e\n\u003cp\u003e其三要属工作之后对自己的思考。这种思绪在上班之后尤为明显。坦率的讲，我现在在一个尴尬的位置与年岁。向往yolo，但不敢轻易改变；想要轰轰烈烈，但又囹囵两点一线。其间见到一些有趣的人，共同的特点是都坚信且贯彻自己的未来目标。这让我意识到我应当做些什么。\u003c/p\u003e\n\u003cp\u003e当然，剩下的时间快乐占据大多数 :)\u003c/p\u003e","title":"Daily | 写在2023年的最后一天"},{"content":" 24 Dec 2023\n✈️： 13:10 -\u0026gt; 20:45\nLondon Luton -\u0026gt; Hurghada 468 GBP 🏠：21:30\nMarina Square Hostel 16 mins by taxi from airport, 10:00 pm checkin approx.) 25 GBP 🥣： 22:00\nMcDonlad\u0026rsquo;s ?\n(2 min walk from hostel) / Or ask stuff\n25 Dec 2023\n🤿：8:30 - 15:30\n50 GBP 🌄：16:30 - 20:00\nStart with a visit to Hurghada Museum Open until 9:00 PM Artfacts from recent Egyptian history Next head to Ad Dahar Souq The most egyptian part of the city Join the through of local shoppers Walking through Marina promenade, Pedestrinised the tourist hub and perfect place for sundown lovers. Passing through Fish souq and Grand Mseque Preview of the dinner supper 🍴：20:30\nEat at Starfish A typical meal includes fish soup, grilled fillets, salad and bread End with a glass of Karkadai (Hibiscus tea) 🍬：21:30\nA short way to Arabic sweet shops A few nuggets of nougat 🏠：22:00\nMarina Square Hostel 13 GBP 26 Dec 2023\n🚌：8:30 -\u0026gt; 12:30\nGo-bus Hurghada -\u0026gt; Luxor 6 GBP 🏠：13:00\nIberotel Luxor 20 mins walk from bus station 39 GBP 🥣：13:30 - 14:00\nA Nile-side resaurant 🔍：14:30 - 16:30\nStart with the visit to the magnificant Karnak\nTour rge 2-sq-km complex of ancient temples Pausing for shai balnaana beside Sacred Lake Stroll back to the centre of town along the Corniche visit after 3pm when the giant pylons turn into gold Approach Karnak via the Avenue of Sphinx from the Temple of Luxor to orient Luxor\u0026rsquo;s two great sights 🌇：17:00 - 19:00\nFelucca Ride on the Nile Opt for a sunset tour instead of banana Island With the afternoon wind bulging the sails and dragging the wooden boats across the water at speed, it’s a thrilling experience. 27 Dec 2023\n🔍: 8:00 - 12:00: Spend the day with the West Bank, greeted by Colossi of Memnon Visiting the hieroglyphics of the Ramesseum Have a local lunch before calling in Carter\u0026rsquo;s House Spend the afternoon by visiting the Valley of the Kings Beat a retreat via the memorial temple of Medinat Habu Relect on a day at a riverside restaurant 🚌：13:00 - 23:00 Luxor - Cairo Go-bus 11 GBP 🏠：23:30 Dahab Hostel 17 GBP 28 Dec 2023\n🔍：7:00 - 17:00\nHead to the Giza Pyrimids for an 8am start Check treasures inside downtown\u0026rsquo;s Egyptian Museum Book a Downtown Food Tour for when finished in Museum Chill out with a shish at an coffee house like Zahret AL Bustan 🏠：19:00\nDahab Hostel\n17 GBP\n29 Dec 2023:\n🚌：Cairo 12:00 to Hurghada 19:00 ✈️: Hurghada 21:20 - London Luton: 1:30 ","permalink":"http://localhost:1313/posts/egypt-/","summary":"\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e24 Dec 2023\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e✈️： 13:10  -\u0026gt; 20:45\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLondon Luton -\u0026gt; Hurghada\u003c/li\u003e\n\u003cli\u003e\u003cem\u003e468 GBP\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🏠：21:30\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMarina Square Hostel\u003c/li\u003e\n\u003cli\u003e16 mins by taxi from airport, 10:00 pm checkin approx.)\u003c/li\u003e\n\u003cli\u003e\u003cem\u003e25 GBP\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🥣： 22:00\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eMcDonlad\u0026rsquo;s ?\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e(2 min walk from hostel) / Or ask stuff\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e25 Dec 2023\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e🤿：8:30 - 15:30\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003e50 GBP\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🌄：16:30 - 20:00\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStart with a visit to \u003cstrong\u003eHurghada Museum\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eOpen until 9:00 PM\u003c/li\u003e\n\u003cli\u003eArtfacts from recent Egyptian history\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eNext head to \u003cstrong\u003eAd Dahar Souq\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eThe most egyptian part of the city\u003c/li\u003e\n\u003cli\u003eJoin the through of local shoppers\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWalking through \u003cstrong\u003eMarina promenade\u003c/strong\u003e,\n\u003cul\u003e\n\u003cli\u003ePedestrinised\u003c/li\u003e\n\u003cli\u003ethe tourist hub and perfect place for sundown lovers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePassing through \u003cstrong\u003eFish souq\u003c/strong\u003e and \u003cstrong\u003eGrand Mseque\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003ePreview of the dinner supper\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🍴：20:30\u003c/p\u003e","title":"Daily | 埃及计划 🇪🇬 Itinerary"},{"content":"入职数月，年关在即。不论我喜欢与否，过去关于学校和工作的起承转合，都已经成为刻画我职业起点的一份记忆。虽是寥寥，但也参与了一次完整的开发周期。其间的感受，冷暖自知，但涌现的经验与反思可贵。趁着记忆新鲜，还是用文字记录。\n学校的任务清晰，明确，甚至有Criteria一一对应，但工作不会。 目标导向，用第一性原理倒推过程，主动思考。 比不懂更可怕的是糊弄。 确保记录，每天的日志比任何时间管理方法都更好用。 期待下月会更好。\n","permalink":"http://localhost:1313/posts/sql-boy%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%9C%88/","summary":"\u003cp\u003e入职数月，年关在即。不论我喜欢与否，过去关于学校和工作的起承转合，都已经成为刻画我职业起点的一份记忆。虽是寥寥，但也参与了一次完整的开发周期。其间的感受，冷暖自知，但涌现的经验与反思可贵。趁着记忆新鲜，还是用文字记录。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e学校的任务清晰，明确，甚至有Criteria一一对应，但工作不会。\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e目标导向，用第一性原理倒推过程，主动思考。\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e比不懂更可怕的是糊弄。\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e确保记录，每天的日志比任何时间管理方法都更好用。\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e期待下月会更好。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://p.ipic.vip/r5b9pi.jpg\" alt=\"IMG_5311\"  /\u003e\n\u003c/p\u003e","title":"Daily | SQL Boy的第一个月"},{"content":"Concept What is a database?\nA structured set of computerized data with accessible interface SQL:\nStructure Query Language (SQL), A standard language used in all relational database management system Install the database\nTwo components:\nMySQL SQL workbench Add the mysql to the environment variable\nopen ~/.zshrc ## add the mysql bin ## no spaces around the = export PATH=${PATH}:/usr/local/mysql/bin ## The save the file source ./zshrc Hierachy:\nServer -\u0026gt; Multiple database -\u0026gt; Multiple sheets Basic Select, Create, Delete\nCREATE DATABASE tea_shop; USE tea_shop; DROP DATABASE tea_shop; -- show current selection SELECT database(); -- show the whole sever SHOW DATABASES; Tables\nCreate: A database is just a bunch of tables (core of the relational database)\nCREATE TABLE cat ( name VARCHAR(50), agen INT ); Query: A collection of related data held in a Structured format within a database\n-- Remember the current cursor is on the database SHOW TABLES; SHOW COLUMNS FROM tea_shop; -- Describ DESC \u0026lt;table name\u0026gt; Drop:\nDROP TABLE \u0026lt;table name\u0026gt;; Insert:\nINSERT INTO \u0026lt;table name\u0026gt; (name, age) VALUE(\u0026#34;JACK\u0026#34;, 10); Data Types\nINT, VARCHAR,.. Basic Attributes of table\nNOT NUlL constrains\nCREATE TABLE cat2 ( name VARCHAR(50) NOT NULL, age INT NOT NULL ); Tips: Use \u0026rsquo; first instead of \u0026quot; to avoid confusion\nDefault Values\nCREATE TABLE cats3 ( name VARCHAR(50) DEFAULT \u0026#39;unnamed\u0026#39;, age INT DEFAULT 99 ); -- Note: The default setting won\u0026#39;t prevent you from inserting the NULL mannually ! Key: We need a unique ID to differentiate the rows even though they looks the same.\nPrimary Key: A unique identifier\nCREATE TABLE unique_cats ( cats_id INT NOT NULL PRIMARY KEY, name VARCHAR(50) DEFAULT \u0026#39;unnamed\u0026#39;, age INT DEFAULT 99 ); -- alternative way CREATE TABLE unique_cats ( cats_id INT NOT NULL, name VARCHAR(50) DEFAULT \u0026#39;unnamed\u0026#39;, age INT DEFAULT 99, PRIMARY KEY(cats_id) ); Auto increament: Only valid for the primary key column\nmysql\u0026gt; CREATE TABLE unique_cat( -\u0026gt; name VAECHAR(50) DEFAULT \u0026#39;unnamed\u0026#39;, -\u0026gt; id INT AUTO_INCREMENT, -\u0026gt; age INT, -\u0026gt; PRIMARY KEY(id)); mysql\u0026gt; DESC unique_cat; +-------+-------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+----------------+ | name | varchar(50) | YES | | unnamed | | | id | int | NO | PRI | NULL | auto_increment | | age | int | YES | | NULL | | +-------+-------------+------+-----+---------+----------------+ 3 rows in set (0.01 sec) String Function **CONCAT() **/ CONCAT_WS (with_seperator):\nSELECT CONCAT(\u0026lt;column name\u0026gt;,\u0026#39; \u0026#39;) AS new_name FROM \u0026lt;table name\u0026gt; SUBSTRING() / SUBSTR()\nSilimiar to the slice operation in Python\nSELECT SUBSTRING(\u0026lt;full string\u0026gt;, \u0026lt;start position\u0026gt;, \u0026lt;end position\u0026gt;) When nesting the query:\nSELECT ... your combination FROM \u0026lt;table name\u0026gt; -- do code beautifier for your co-worker :) REPLACE()\nSELECT REPLACE (\u0026#39;hello world\u0026#39;, \u0026#39;hell\u0026#39;, \u0026#39;*Q#Q*\u0026#39;); -- Case sensitive REVERSE()\nSELECT REVERSE (\u0026#39;长恨送年芳\u0026#39;); CHAR_LENGTH()\n## LENGTH mearsures in bits mysql\u0026gt; SELECT -\u0026gt; LENGTH(\u0026#39;海豚\u0026#39;); +------------------+ | LENGTH(\u0026#39;海豚\u0026#39;) | +------------------+ | 6 | +------------------+ 1 row in set (0.00 sec) mysql\u0026gt; SELECT -\u0026gt; CHAR_LENGTH(\u0026#39;海豚\u0026#39;); +-----------------------+ | CHAR_LENGTH(\u0026#39;海豚\u0026#39;) | +-----------------------+ | 2 | +-----------------------+ 1 row in set (0.00 sec) UPPER/ UCASE and LOWER/LCASE\nINSERT\nREPEAT\nTRIM\nmysql\u0026gt; SELECT TRIM( TRAILING \u0026#39;.\u0026#39; FROM \u0026#39;..em..\u0026#39; ); +------------------------------------+ | TRIM( TRAILING \u0026#39;.\u0026#39; FROM \u0026#39;..em..\u0026#39; ) | +------------------------------------+ | ..em | +------------------------------------+ 1 row in set (0.00 sec) Pratice time 🙌\nTips on writting function:\nAlways following a \u0026lsquo;(\u0026rsquo; after the calling function, do not leave the space. E.g. This will cause error:\n## Error demostration mysql\u0026gt; SELECT TRIM (LEADING \u0026#39;.\u0026#39; FROM \u0026#39;...emmm...\u0026#39;); ## Instead: mysql\u0026gt; SELECT TRIM(LEADING \u0026#39;.\u0026#39; FROM \u0026#39;...emmm...\u0026#39;); +-------------------------------------+ | TRIM(LEADING \u0026#39;.\u0026#39; FROM \u0026#39;...emmm...\u0026#39;) | +-------------------------------------+ | emmm... | +-------------------------------------+ 1 row in set (0.00 sec) Put the Aliases name in to \u0026rsquo; \u0026rsquo; although the single word without quotation marks can be encoded correctly\nFunction Cheatsheet\nSelection select distinct elements\nSELECT DISTINCT \u0026lt;column name\u0026gt; FROM \u0026lt;table name\u0026gt;; -- DISTINCT Applies to all following keys ORDER BY\nSELSELECT DISTINC author_lname, author_fname FROM books ORDER BY author_lname DESC; -- ORDER BY 2 (2nd selected columns) -- ORDER BY author_lname, author_fname LIMIT: limit the number of query return\nSELECT DISTINC author_lname, author_fname FROM books ORDER BY author_lname DESC LIMIT 5,10; -- LIMITE from 5 to 10th row SEARCH: searching the characture\nSELECT title, author_lname FROM books WHERE author_lname LIKE \u0026#34;%da%\u0026#34;; -- r\u0026#39;%\u0026#39;\u0026#39; is equivlent to r\u0026#39;.*\u0026#39; in regular expression SQL search cheatsheet % == .* _ == . \u0026#39; == $ (at the end of the string) \\ == \\ (转义) Pratice time 🙌\nTips:\nSELECT \u0026lt;colum name\u0026gt; AS another_name FROM books -- AS goes first before FROM CRUP CRUD: Create, Read, Update, Delete\nRead:\nConditional Statement: WHERER\nSELECT \u0026lt;column name\u0026gt;, \u0026lt;column name\u0026gt; FROM \u0026lt;table name\u0026gt; WHERE \u0026lt;BOOL expression\u0026gt;;\tAliases Statement: AS, Temporary only for this query\nmysql\u0026gt; SELECT name AS kettyname FROM cats; +----------------+ | kettyname | +----------------+ | Ringo | | Cindy | | Dumbledore | | Egg | | Misty | | George Michael | | Jackson | +----------------+ Update:\nAlways from a table prospect using the SQL\nUPDATE \u0026lt;able name\u0026gt; SET \u0026lt;cloumn name\u0026gt; = \u0026lt;value\u0026gt; WHERE ... Rule of 👍: Try selecting before update. Make sure your target is correct.\nNotice the data type when amending.\nDelete (Destroy:/ ):\nDELETE FROM \u0026lt;table name\u0026gt; WHERE .. Notice the difference from DROP: DELETE will at least leave an empty set.\nTry Selecting before as well.\nPratice time 🙌\nLeave enough space when naming each column. If not:\n-- modify the attributes of column ALTER \u0026lt;table name\u0026gt; MODIFY COLUMN \u0026lt;column name\u0026gt; \u0026lt;new data type\u0026gt; The PRIMARY KEY setting will set NOT NULL by default\nData Type (Time) Text\nDecimal DECIMAL(5,2)\nFLoat\nDATE: YYYY-MM-DD\nTIME: hh:mm:ss\nDATETIME: YYYY-MM-DD hh:mm:ss\nCURDATE / CURTIME / NOW\nIFNULL(\u0026lt;column name\u0026gt;, replacement)\nTime Stamp : Similar to datetime by only supports much smaller range\nOn update: one more extra\nmysql\u0026gt; DESC caption; +-----------+--------------+------+-----+-------------------+-----------------------------+ | Field | Type | Null | Key | Default | Extra | +-----------+--------------+------+-----+-------------------+-----------------------------+ | text | varchar(200) | YES | | NULL | | | create_at | timestamp | YES | | CURRENT_TIMESTAMP | DEFAULT_GENERATED | | update_at | timestamp | YES | | NULL | on update CURRENT_TIMESTAMP | +-----------+--------------+------+-----+-------------------+-----------------------------+ mysql\u0026gt; INSERT INTO caption (text) VALUES(\u0026#39;hello\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; SELECT * FROM caption; +-------+---------------------+-----------+ | text | create_at | update_at | +-------+---------------------+-----------+ | hello | 2023-06-16 14:38:47 | NULL | +-------+---------------------+-----------+ mysql\u0026gt; UPDATE caption SET text = \u0026#39;hello!!\u0026#39;; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; SELECT * FROM caption; +---------+---------------------+---------------------+ | text | create_at | update_at | +---------+---------------------+---------------------+ | hello!! | 2023-06-16 14:38:47 | 2023-06-16 14:39:37 | +---------+---------------------+---------------------+ Change the format of time:\nDATE_FORMAT\nmysql\u0026gt; SELECT DATE_FORMAT(NOW(), \u0026#39;%d-%m-%Y\u0026#39;); +--------------------------------+ | DATE_FORMAT(NOW(), \u0026#39;%d-%m-%Y\u0026#39;) | +--------------------------------+ | 16-06-2023 | +--------------------------------+ format Ref\nLogical Operation Not equal !=\nNot like NOT LIKE\nGreater than \u0026gt;\nAND AND\nOR OR\nBETWEEN BETWEEN .. AND ...\nIN IN: (NOT IN as well)\nWHERE author_lname IN (\u0026#39;Bobby\u0026#39;, \u0026#39;Baobi\u0026#39;, \u0026#39;Buobi\u0026#39;) CASE STATMENT\nSELECT title, released_year, CASE WHEN released_year \u0026gt;= 2000 THEN \u0026#39;Morden lit\u0026#39; WHEN .. THEN .. WHEN .. THEN .. ELSE .. END AS .. FROM books; IS NULL\nAggregation Count\nSELECT COUNT(author_laname) FROM books -- COUNT(*) has only_form_by_whole_group attribute -- COUNT omits the NULL values Group By (the result is like clustering)#\nmysql\u0026gt; SELECT COUNT(*) FROM books GROUP BY author_lname; +----------+ | COUNT(*) | +----------+ | 2 | | 3 | | 3 | | 1 | | 1 | | 2 | | 1 | | 1 | | 2 | | 2 | | 1 | +----------+ 11 rows in set (0.00 sec) mysql\u0026gt; SELECT COUNT(*) FROM books; +----------+ | COUNT(*) | +----------+ | 19 | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; SELECT * FROM books GROUP BY author_lname; ERROR 1055 (42000): Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column \u0026#39;book_shop.books.book_id\u0026#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by mysql\u0026gt; SELECT author_lname FROM books GROUP BY author_lname; +----------------+ | author_lname | +----------------+ | Lahiri | | Gaiman | | Eggers | | Chabon | | Smith | | Carver | | DeLillo | | Steinbeck | | Foster Wallace | | Harris | | Saunders | +----------------+ 11 rows in set (0.00 sec) # notice how * refers to different targets when using GROUP BY mysql\u0026gt; SELECT CONCAT(author_lname,\u0026#39; \u0026#39;,author_fname) AS author FROM books GROUP BY author; +----------------------+ | author | +----------------------+ | Lahiri Jhumpa | | Gaiman Neil | | Eggers Dave | | Chabon Michael | | Smith Patti | | Carver Raymond | | DeLillo Don | | Steinbeck John | | Foster Wallace David | | Harris Dan | | Harris Freida | | Saunders George | +----------------------+ 12 rows in set (0.00 sec) MIN/MAX\nSub query\nmysql\u0026gt; SELECT title, pages FROM books WHERE pages=(SELECT MAX(pages) FROM books); +-------------------------------------------+-------+ | title | pages | +-------------------------------------------+-------+ | The Amazing Adventures of Kavalier \u0026amp; Clay | 634 | +-------------------------------------------+-------+ 1 row in set (0.00 sec) Group BY + MIN/Max\n## Not working :( mysql\u0026gt; SELECT author_lname, released_year -\u0026gt; FROM books -\u0026gt; GROUP BY author_lname; ERROR 1055 (42000): Expression #2 of SELECT list is not in GROUP BY clause and contains nonaggregated column \u0026#39;book_shop.books.released_year\u0026#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by ## working :) mysql\u0026gt; SELECT author_lname, MIN(released_year) -\u0026gt; FROM books -\u0026gt; GROUP BY author_lname; +----------------+--------------------+ | author_lname | MIN(released_year) | +----------------+--------------------+ | Lahiri | 1996 | | Gaiman | 2001 | | Eggers | 2001 | | Chabon | 2000 | | Smith | 2010 | | Carver | 1981 | | DeLillo | 1985 | | Steinbeck | 1945 | | Foster Wallace | 2004 | | Harris | 2001 | | Saunders | 2017 | +----------------+--------------------+ 11 rows in set (0.00 sec) Notice the concept of Aggregation Function, Group By only works with the aggregation functions (MIN/MAX/SUM/AVG)\nReference: https://dev.mysql.com/doc/refman/8.0/en/aggregate-functions.html\nConstrains \u0026amp; Alter Unique\nCREATE TABLE contacts ( Name VARCHAR(150) NOT NULL, Phone VARCHAR(12) NOT NULL UNIQUE ); mysql\u0026gt; DESC contacts; +-------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+---------+-------+ | Name | varchar(150) | NO | | NULL | | | Phone | varchar(12) | NO | PRI | NULL | | +-------+--------------+------+-----+---------+-------+ Check / Constrains\nCREATE TABLE partiers ( Name VARCHAR(150) NOT NULL, Age INT NOT NULL CHECK (age \u0026gt; 18) ); -- Equivlent CREATE TABLE partiers ( Name VARCHAR(150) NOT NULL, Age INT NOT NULL, CONSTRAINT adult_check CHECK (Age \u0026gt; 18) ); Multi-column Constrains\nCREATE TABLE companies ( name VARCHAR(150) NOT NULL, address VARCHAR(300) NOT NULL, CONSTRAINT name_address UNIQUE(name, address) ); ALL in one place to change the attribute of the table: ALTER\n-- Add a column ALTER TABLE companies ADD COLUMN type VARCHAR(50) NOT NULL DEFAULT \u0026#39;Ltd\u0026#39;; -- Drop a column ALTER TABLE companies DROP COLUMN type VARCHAR(50) NOT NULL DEFAULT \u0026#39;Ltd\u0026#39;; -- Rename a table ALTER TABLE companies RENAME TO \u0026#39;\u0026#39;suppliers -- Rename a column ALTER TABLE companies RENAME COLUMN type TO Categories -- Modify the existing column ALTER TABLE companies MODIFY COLUMN \u0026lt;new constraint\u0026gt; Tips: Check all constraints\nSELECT * FROM USER_CONSTRAINTS -- It will return all constraints in the selected database One 2 Many How to manage the data ? by relationship:\nOne to one relationship table 1: basic info of customers | table2: details of customers | customer as the key One to Many relationship (*) One book to many of reviews Many to many relationship Books and authors: books can have multiple authors, the author can also have many books One to many: Take customers and orders for example:\nPrimary Key: Some particular column that always unique\nForeign Key: Reference to other table\n-- how to use foreign key to link two tables? -- table 1 CREATE TABLE customers ( id INT PRIMARY KEY AUTO_INCREMENT, first_name VARCHAR(50), last_name VARCHAR(50), email VARCHAR(50) UNIQUE); -- table 2 CREATE TABLE orders( id INT PRIMARY KEY AUTO_INCREMENT, order_date DATE,DES customer_id INT, FOREIGN KEY (customer_id) REFERENCES customers(id) ); Cross Join: dummy emmumerated combination of two table\nInner Join:\nSELECT * FROM customers JOIN orders on orders.customer_id = customers.id; mysql\u0026gt; SELECT * FROM customers JOIN orders on orders.customer_id = customers.id; +----+------------+-----------+------------------+----+------------+--------+-------------+ | id | first_name | last_name | email | id | order_date | amount | customer_id | +----+------------+-----------+------------------+----+------------+--------+-------------+ | 1 | Boy | George | george@gmail.com | 1 | 2016-02-10 | 99.99 | 1 | | 1 | Boy | George | george@gmail.com | 2 | 2017-11-11 | 35.50 | 1 | | 2 | George | Michael | gm@gmail.com | 3 | 2014-12-12 | 800.67 | 2 | | 2 | George | Michael | gm@gmail.com | 4 | 2015-01-03 | 12.50 | 2 | | 5 | Bette | Davis | bette@aol.com | 5 | 1999-04-11 | 450.25 | 5 | +----+------------+-----------+------------------+----+------------+--------+-------------+ 5 rows in set (0.00 sec) Left Join / Right join:\nSELECT * FROM customers LEFT JOIN orders on orders.customer_id = customers.id; mysql\u0026gt; SELECT * FROM customers LEFT JOIN orders on orders.customer_id = customers.id; +----+------------+-----------+------------------+------+------------+--------+-------------+ | id | first_name | last_name | email | id | order_date | amount | customer_id | +----+------------+-----------+------------------+------+------------+--------+-------------+ | 1 | Boy | George | george@gmail.com | 1 | 2016-02-10 | 99.99 | 1 | | 1 | Boy | George | george@gmail.com | 2 | 2017-11-11 | 35.50 | 1 | | 2 | George | Michael | gm@gmail.com | 3 | 2014-12-12 | 800.67 | 2 | | 2 | George | Michael | gm@gmail.com | 4 | 2015-01-03 | 12.50 | 2 | | 3 | David | Bowie | david@gmail.com | NULL | NULL | NULL | NULL | | 4 | Blue | Steele | blue@gmail.com | NULL | NULL | NULL | NULL | | 5 | Bette | Davis | bette@aol.com | 5 | 1999-04-11 | 450.25 | 5 | +----+------------+-----------+------------------+------+------------+--------+-------------+ # Notice some customer doesn\u0026#39;t have order info but still be merged into the new table Delete with the foriegn key constraints\n-- table 2 CREATE TABLE orders( id INT PRIMARY KEY AUTO_INCREMENT, order_date DATE,DES customer_id INT, FOREIGN KEY (customer_id) REFERENCES customers(id) ON DELETE CASECADE ); View VIEWS\nCreating a cache table CREATE VIEW new_list AS SELECT ... Can \u0026amp; Can\u0026rsquo;t can\u0026rsquo;t: Join, Update (Depend on the view table type ) Over-write to correct CREATE OR REPLACE VIEW ... GROUP BY HAVING:\nSilimar to WHERE but applied withGROUP BY GROUP BY WITH ROLLUP:\nThe Aggrigation of aggrigation SQL MODES\nSELECT @@GLOBAL.sql_mode SET GLOBAL sql_mode=\u0026#39;modes\u0026#39; SELECT @@SESSION.sql_mode SET SESSION sql_mode = \u0026#39;mode,..\u0026#39; +-----------------------------------------------------------------------------------------------------------------------+ | @@GLOBAL.sql_mode | +-----------------------------------------------------------------------------------------------------------------------+ | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION | +-----------------------------------------------------------------------------------------------------------------------+ Modes: STRICT_TRANS_TABLES: Strict constraints on the data type conversion ONLY_FULL_BY: Window function Window function\nSilimar to window function But append aggregation results on each row OVER( PARTITION BY )\nmysql\u0026gt; SELECT department, salary, AVG(salary) OVER(x BY department) FROM employees; +------------------+--------+-------------------------------------------+ | department | salary | AVG(salary) OVER(PARTITION BY department) | +------------------+--------+-------------------------------------------+ | customer service | 38000 | 46571.4286 | | customer service | 45000 | 46571.4286 | | customer service | 61000 | 46571.4286 | | customer service | 40000 | 46571.4286 | | customer service | 31000 | 46571.4286 | | customer service | 56000 | 46571.4286 | | customer service | 55000 | 46571.4286 | | engineering | 80000 | 81285.7143 | | engineering | 69000 | 81285.7143 | OVER( ORDER BY): rolling style mysql\u0026gt; SELECT department, salary, SUM(salary) OVER(PARTITION BY department ORDER BY salary ASC) AS depart_avg_rolling, SUM(salary) OVER(PARTITION BY department) as depart_avg FROM employees; +------------------+--------+--------------------+------------+ | department | salary | depart_avg_rolling | depart_avg | +------------------+--------+--------------------+------------+ | customer service | 31000 | 31000 | 326000 | | customer service | 38000 | 69000 | 326000 | | customer service | 40000 | 109000 | 326000 | | customer service | 45000 | 154000 | 326000 | | customer service | 55000 | 209000 | 326000 | | customer service | 56000 | 265000 | 326000 | | customer service | 61000 | 326000 | 326000 | | engineering | 67000 | 67000 | 569000 | | engineering | 69000 | 136000 | 569000 | | engineering | 70000 | 206000 | 569000 | | engineering | 80000 | 286000 | 569000 | RANK() OVER( ORDER BY) mysql\u0026gt; SELECT department, salary,RANK() OVER(PARTITION BY department ORDER BY salary DESC) AS depart_rank, RANK() OVER(ORDER BY salary DESC) AS over_rank FROM employees; +------------------+--------+-------------+-----------+ | department | salary | depart_rank | over_rank | +------------------+--------+-------------+-----------+ | sales | 159000 | 1 | 1 | | engineering | 103000 | 1 | 2 | | engineering | 91000 | 2 | 3 | | engineering | 89000 | 3 | 4 | | engineering | 80000 | 4 | 5 | | sales | 72000 | 2 | 6 | | engineering | 70000 | 5 | 7 | | sales | 70000 | 3 | 7 | | engineering | 69000 | 6 | 9 | | engineering | 67000 | 7 | 10 | NTLE\nFIRST VALUE\nLAG: Shift down for 1 row\n","permalink":"http://localhost:1313/posts/sql-concept/","summary":"\u003ch2 id=\"concept\"\u003eConcept\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eWhat is a database?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA \u003cstrong\u003estructured\u003c/strong\u003e set of computerized data with \u003cstrong\u003eaccessible interface\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSQL:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStructure Query Language (SQL), A standard language used in all relational database management system\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInstall the database\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTwo components:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eMySQL\u003c/li\u003e\n\u003cli\u003eSQL workbench\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAdd the mysql to the environment variable\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eopen ~/.zshrc\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e## add the mysql bin\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e## no spaces around the = \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ePATH\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"nv\"\u003ePATH\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e:/usr/local/mysql/bin\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e## The save the file\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003esource\u003c/span\u003e ./zshrc\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHierachy:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eServer -\u0026gt; Multiple database -\u0026gt; Multiple sheets\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"basic\"\u003eBasic\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSelect, Create, Delete\u003c/strong\u003e\u003c/p\u003e","title":"Note | Quick Notes on SQL"},{"content":"Common Terminologies in Graph Thoery Define an undirected graph with the natrual order as $G = (V,E,\\sigma)$ where $V$ is the set of the vertices, $E$ is the set of edges and $\\sigma$ is the natrual ordering.\nChordal graph\nA chordal is a path of undirected graph between two non-conescutive vertices. (\u0026ldquo;shortcut\u0026rdquo;\u0026quot; between two vertices\u0026quot;) A chordal graph referes to every cycle of length four or greater of a simple graph has a chord. (triangulated graph) Chordal Completion\nThe triangualtion result of an undirected graph, it is a chordal graph Filled Graph\nAn undirected graph $G$ is filled graph if any two higher order neighbours of any vertex in $G$ induce an edge $$ w,z\\in adj^+(G) \\rightarrow {w,z}\\in E $$ Elimination order\nAn elimination ordering $\\sigma$ is a numbering of the vertices of $G$ from 1 to n. The fill-in $F_{\\sigma}$, caused by the ordering $\\sigma$ is the set of edges defined as: $F={{w,v}|w\\neq v, {w,v}\\neq E}$ Perfect Elimination Order\n$\\sigma$ is perfect if $F_\\sigma=\\phi$ $\\sigma ^$ is the perfect elimination order if $G=(V,E,\\sigma ^)$ is a filled graph. (Eliminate by this order wouldn\u0026rsquo;t create any new chordal) A graph is chordal if and only if it has a perfect elimination order Complete Graph\nA graph is complete if all vertices are pair-wise advanct Clique\nA clique is a subgraph of $G$ that is complete Simplicial Vertex\nA simplicial vertex is one whose neighbours forms a clique Vertex seperator\nIf $S$ is a subset of the vertices: $S\\in V$, $G(V\\backslash S)$ is the subgraph of $G$ induced by $S$; if $G(V\\backslash S)$ is disconnected, $S$ is a separator. Clique Tree\nA clique tree of a graph G = (V,E) is a tree which has the cliques of G as its vertices. Block (Read more from this paper)\nthe set of minimal seperator $S\\in\\triangle(G)$ the set of connected componets w.r.t $S$: $\\mathcal{C}_G(S)$ The component is a full component with S if every vertex of S is adjacent to some vertex of C. If $C\\in\\mathcal{C}(S)$, $(S,C)=S\\cup C$ a block associated with S The block is called full if C is a full component associated with S The Difference between Minimal and Minimum\nSince the problem of computing minimum triangulations is NP-hard, the related polynomially solvable problem of computing minimal triangulations became interesting, and the first algorithms for it appeared in 1976\nIt should be emphasized here that the word “optimal” should not be mistaken to mean “optimum” as in some engineering literature. In terms of a set, “optimal” refers to a set property, whereas “optimum” refers to the size of the set.\n\u0026mdash;Minimal Triangulation of a Graph and Optimal Pivoting Order in a Sparse Matrix (Ohtsuki, etc, 1976)\nBlock realisation\nPotential Maximal Clique: a potential maximal clique if there is a minimal triangulation H of G such that Ω is a maximal clique of H.\n","permalink":"http://localhost:1313/posts/common-terminologies-in-graph-thoery/","summary":"\u003ch1 id=\"common-terminologies-in-graph-thoery\"\u003eCommon Terminologies in Graph Thoery\u003c/h1\u003e\n\u003cp\u003eDefine an undirected graph with the natrual order as $G = (V,E,\\sigma)$ where $V$ is the set of the vertices, $E$ is the set of edges and $\\sigma$ is the natrual ordering.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eChordal graph\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA \u003cstrong\u003echordal\u003c/strong\u003e is a path of undirected graph between two non-conescutive vertices. (\u0026ldquo;shortcut\u0026rdquo;\u0026quot; between two vertices\u0026quot;)\u003c/li\u003e\n\u003cli\u003eA \u003cstrong\u003echordal graph\u003c/strong\u003e referes to every cycle of length four or greater of a simple graph has a chord. (triangulated graph)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eChordal Completion\u003c/strong\u003e\u003c/p\u003e","title":"Note | Common Terminologies in Graph Thoery"},{"content":"Clique seperator Decomposition by clique seperator (Tarjan, 1985) Main Idea: Based on the idea of \u0026lsquo;divide and conquer\u0026rsquo;, this paper proposed an graph decomposition algorithm by finding the clique seperator recursively. The decomposition results in a binary decomposition tree. The author suggested some general ideas to tackle 4 NP-hard problems by ultlizing the binary decomposition tree.\nPreliminaries Perfect elimination ordering, Clique, Minimal and Minimum ordering, Seperator\nAlgorithms Text description\nCorollary: If we can find the perfect ordering on atoms, then we can find the perfect ordering on the entire graph Proof:\nLet Atoms be $G_i=(V_i, E_i)\\ \\forall i=1,\\cdots,k$.\nWe first compute the fill-in $F_i$ on $G_i$ produced by $\\sigma_i$. Since $G_i\u0026rsquo;=(V_i, E_i\\cup F_i)$ is chordal, so is $G\u0026rsquo;=(V, E\\cup \\cup_{i=1}^kF_i)$.\nNext, We compute the perfect ordering $\\sigma$ on $G\u0026rsquo;$, the resulted fill-in is the subset of $\\cup_{i=1}^kF_i$. Thus, $\\sigma$ is minimum if $\\sigma_i$ is minimum for all $i$\nAlgorithms to generate graph with the perfect ordering ","permalink":"http://localhost:1313/posts/decomposition-by-clique-seperator/","summary":"\u003ch1 id=\"clique-seperator\"\u003eClique seperator\u003c/h1\u003e\n\u003ch2 id=\"decomposition-by-clique-seperator-tarjan-1985httpsscholargooglecomcitationsuserlazjixiaaaajhlzh-cnoisra\"\u003eDecomposition by clique seperator (\u003ca href=\"https://scholar.google.com/citations?user=lazJixIAAAAJ\u0026amp;hl=zh-CN\u0026amp;oi=sra\"\u003eTarjan, 1985\u003c/a\u003e)\u003c/h2\u003e\n\u003ch3 id=\"main-idea\"\u003eMain Idea:\u003c/h3\u003e\n\u003cp\u003eBased on the idea of \u0026lsquo;divide and conquer\u0026rsquo;, this paper proposed an graph decomposition algorithm by finding the clique seperator recursively. The decomposition results in a binary decomposition tree. The author suggested some general ideas to tackle 4 NP-hard problems by ultlizing the binary decomposition tree.\u003c/p\u003e\n\u003ch3 id=\"preliminaries\"\u003ePreliminaries\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003ePerfect elimination ordering\u003c/em\u003e, \u003cem\u003eClique\u003c/em\u003e, \u003cem\u003eMinimal and Minimum ordering\u003c/em\u003e, \u003cem\u003eSeperator\u003c/em\u003e\u003c/p\u003e\n\u003ch3 id=\"algorithms\"\u003eAlgorithms\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003e\u003ca href=\"https://scholar.google.com/citations?user=lazJixIAAAAJ\u0026amp;hl=zh-CN\u0026amp;oi=sra\"\u003eText description\u003c/a\u003e\u003c/p\u003e","title":"Note | Clique seperator"},{"content":"Overview Revisitting the sparse matrix technology - Summary.\nProblem Statement we wish to solve $$ Ax=b $$ with $A$ sparse and symmetric. If $P$ is a permuation matrix, the system of linear equation can be writtem: $$ PAP^TPx=Pb $$ or if $B=PAP^T$, $y=Px$ , and $c=Pb$ $$ By=c $$ where $B$ is the permeated form of $A$ it is also sparse and symmetric. If $A$ is positive definite, $B$ is also positive definite.\nThe amount of fill-in requred to factorize $B$ depend on $P$. Our goal is to find a convinient $P$ that results in the least possible fill-in after factorisation. $$ argmin_{P}\\ ||L||_0\\ s.t\\ \\ \\ \\ PAP^T = LL^T\\ Ax =b\\ $$\nMotivation of different algorithms Minimum ordering algorithm Fill-in are produced during the column elimination.\nIn order to reduce the number of nonzeros in the i-th column, a natrual idea is to move the column with the fewest nonzeros from the submatrix to the i-th column at each step.\nIt always prioritizes the nodes with the minimum degree from the unlabelled nodes. One further enhancement method can be referred to the operations on indistinguishable nodes\nReverse Cuthill-McKee (RCM) algorithm All arithmetic is confined to band and no new zero elements are generated outside of the band.\nTo minimize the bandwidth of the row associated with z, node z should be ordered as soon as possible after y\nThe Cuthill-McKee scheme can be regarded as a method that reduces the bandwidth of a matrix via a local minimization of the $\\beta_i$\u0026rsquo;s.\nIn RCM algorithms: The bandwidth is compressed via a greedy method $$ min\\ \\beta(A) \\rightarrow\\ min \\sum_i\\beta_i(A) $$ The way to find the starting point is also a heuristic method\nNested Dissection Algorithm Ad: speed, predicitable storage requirement\nOur purpose is to preserve as many zero entries as possible. Here we create zero blocks as much as possible by using seperators.\nAlgorithms Minimum Degree\nRCM\nNested Dissection\nComparsion Experiment results Test case 1: 100x100 mesh matrix\nTest case 2: 200x200 random sparse matrix generated by Scipy\nFurther comparsion\nEvaluation metrics It is more or less self-evident that for some classes of problems, one method may be uniformly better than all others, or that the relative merits of the methods in one sector may be entirely different for other classes of problems.\nOperations (multiplications and divisions) measures the amount of arithmetic performed\n​\tBackground $$ Ax=b\\ LL^Tx=b\\ Ly=b\\ L^Tx=y $$\nOnce computed the factorisation, we must solve the triangular systems via $Ly=b$ and $L^Tx=y$\n![image-20230426133539682](/Users/duanwenbo/Library/Application Support/typora-user-images/image-20230426133539682.png)\nAlternatively we can compute via the column-wise operation\nFor a triangular system $Tx=b$, For $i = 1,2,\\cdots,n,$ $$ x_i = (b_i-\\sum_{k=1}^{i-1}t_{i,k}x_k)/t_{i,i} $$\nTerminology\nFor a given matrix $A$, let $A_{i}$ and $A_{i}$ denotes i-th column and i-th row respectively\nLet $\\mu(A)$ denotes the number of non-zeros componets of A\nThe number of operations required to solve for $x$ (Equal or less than the nonzeros of the decomposed components) $$ \\sum_i{\\mu(T_{*i})|x_i\\neq0} $$\nExcecution Time: 4 phases:\nOrdering: Finding a good $P$ Storage allocation Factorizing the permutated matrix Triangular solution Storage\nCost(S, T, \u0026hellip;.)\nExample test data from book\nSource: chapter 9 of Computer solution of Sparse Linear system, 1994\nThere is no simple answer for which algorithms is better, it varies a lot based on the type of the problem, the optimization goal , the size of the problem and the data structure. Nested Dissection tend to be superior to minimum degree for large problems that come from 2D to 3D spatial descretization. Profile reduction method is one of the earlest method which has a direct impact on the memory usage. See more comments from chapter 7.7 of Direct Method for Sparse Linear systems, 2006\n","permalink":"http://localhost:1313/posts/revisiting-sparse-matrix-technologies/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eRevisitting the sparse matrix technology - Summary.\u003c/p\u003e","title":"Note | Revisiting Sparse Matrix Technologies"},{"content":"Overview Revisitting the sparse matrix technology.\nReverse Cuthill-McKee Algorithm (George, Liu, etc. 1981) Terminology Let A be an $n\\times n$ symmetric positive matrixm with entries $a_{ij}$\n$f_i(A)$ denotes the column substrcipt of the first non-zero component in row $i$ of A: $$ f_i(A) = min{j|a_{ij}\\neq 0} $$ $\\beta_i(A)$ denotes the i-th bandwidth of A: $$ \\beta_i(A) = i -f_i(A) $$ $\\beta(A)$ denotes the bandwith of A: $$ \\beta(A) = \\max {\\beta_i(A)|1\\le i \\le n} $$ $Env(A)$ denotes the envelop of A: $$ Env(A) = {{i,j}|0\u0026lt;i-j\\le\\beta_i(A} $$\nEnvelop size = $|Env(A)|$\n$w_i(A)$ denotes the i-th frontwidth of A, the number of \u0026ldquo;active\u0026rdquo; rows at i-th step: $$ w_i(A) = |{j\u0026gt;i|{i,j}\\in Env(A)}| $$ Frontwidth : $w(A) = \\max{w_i(A)|1\\le i\\le n }$\nDefine Eccentricity $l(x)$ as the maximum distance that root $x$ could reach within the graph: $$ l(x) = max{d(x,y)|y\\in X} $$\nA node $x\\in X$ is said to be a peripheral nodes if its eccentricity is equal to the diameter of the graph.\nTheorem The Adjacent set $Adj({x_1,\\cdots,x_i})$ shall be referred to as the i-th front of the labelled graph, and its size the i-th frontwidth $$ For\\ i\u0026lt;j,{i,j}\\in Env(A)\\ if\\ and\\ only\\ if\\ x_j\\in Adj({x_1,\\cdots,x_i}) $$ Algorithm Discussion How the bandwidth and envelop of the matrix affects the fill-in ?\nWhen a system of linear equations has a band matrix of coefficients and the system is solved by Guassian elimination, with pivots taken from the diagonal, all arithmetic is confined to band and no new zero elements are generated outside of the band.\nTo minimize the bandwidth of the row associated with z, node z should be ordered as soon as possible after y.\nGreedy policy: The Cuthill-McKee scheme can be regarded as a method that reduces the bandwidth of a matrix via a local minimization of the $\\beta_i$\u0026rsquo;s. This suggests that the scheme can be used as a method to reduce the profile/envelope\nWhy reverse ?\nReversing the Cuthill-McKee ordering ofren turns out to be much superior to the original ordering in terms of profile reduction, although tha bandwidth remains unchanged. Heuristic searching for peripheral node\nPeripheral node is the ideal starting point in RCM and many other algorithms, while it is expensive to find with the time complexity bound of $O(|X|^2)$. Instead we search the pseudo-peripheral node by iterating in the level strcture of the graph. Implementation RCM algorithm\nCode\ndef RCM(G): \u0026#34;\u0026#34;\u0026#34; RCM algorithm :param G: Graph :return: a list of reordered index \u0026#34;\u0026#34;\u0026#34; def single_seach(G): # Breadth first search root = diameter_pair_algo(G) que = deque() que.append(root) visited = [root] while que: for _ in range(len(que)): root = que.popleft() adjacencies = G.adj[root].keys() subsidiaries = [node for node in adjacencies if node not in visited] for sub in subsidiaries: que.append(sub) visited.append(sub) return visited[::-1] reordered = [] sub_graphes = subGraphs(G) for sub_graph in sub_graphes: if len(list(sub_graph.nodes)) \u0026lt;= 1: reordered += list(sub_graph.nodes) else: reordered += single_seach(sub_graph) return reordered Finding pseudo-peripheral nodes\nCode\ndef diameter_pair_algo(G) -\u0026gt; set: \u0026#34;\u0026#34;\u0026#34; pseudo-peripheral algorithsm (George, Liu, 1994) find one pseudo-diameter pair :param G: Networkx undirected graph :return: a pseudo-peripheral vertex \u0026#34;\u0026#34;\u0026#34; s = np.random.choice(G.nodes) while True: level_set_s = level_set_algo(G,s) # choose a node in the last level set of minimum degree nodes = [(i,G.degree[i]) for i in level_set_s[-1]] t = min(nodes, key = lambda x: x[1])[0] level_set_t = level_set_algo(G,t) if len(level_set_t) \u0026gt; len(level_set_s): s = t return t ","permalink":"http://localhost:1313/posts/reverse-cuthill-mckee-algorithm/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eRevisitting the sparse matrix technology.\u003c/p\u003e","title":"Note | Reverse Cuthill-McKee Algorithm"},{"content":"Overview Revisitting the sparse matrix technology.\nLevel set based Nested Dissection （George, 1973） 1. Essential terminology Given undirected graph $G(V,E)$:\nThe Path is an ordered set of distinct vertices Eg: A path of length K = ${v_1,v_2,\\cdots,v_k,v_{k+1}}$ The Distance between two vertices u and v: $dist(u,v)$ is the length of the shorest path $dist(u,v)$ = shorest path The Diameter of graph $G$ is the maximum distance between ANY two vertices in the graph: $diam(G)=max_{u,v\\in G}\\ dist(u,v)$ A vertex $v$ is Extremal with respect to a vertex $u$ if v is as far away from u as possible: $dist(u,v) = max_{w}\\ dist(u,w)$ When two vertices u and v are mutually extremal \u0026lt;=\u0026gt; They form a pseudo-diameter pair \u0026lt;=\u0026gt; u and v are both pseudo-peripheral vertices: $dist(u,v)=max_w\\ dist(u,w) = max_v\\ dist(v,w)$ Level sets: GIVEN ANY VERTEX $s$ FROM GRAPH: One level set is the collection of vertices with the same distance from $s$: $v\\in L_i(s)$ if and only if $dist(v,s)=i$ The Level sets of a root vertex $s$: $L(s)={L_0(s), L_1(s),\\cdots,L_k(s)}$ 2. Vanilla Nested Dissection 2.1 Some useful conclusions FACT 1 Each level set defines a separator\nAn edge occurs only when two vertices belong to the same level set or to adjacent level sets FACT 2 A good seperator should be as small as possible\nSmall separators cause the shaded areas associated with the S-sets to be small FACT 3 Using a pseudo-peripheral vertex as the root is more likely to find a good seperator.\nA level structure rooted at a pseudoperopheral vertex is likely to have many levels 2.2 Algorithm Phase 1: Finding the pseudoperopheral vertices (Mutual extremal)\nCode\ndef diameter_pair_algo(G) -\u0026gt; set: \u0026#34;\u0026#34;\u0026#34; find one pseudo-diameter pair : param G: Graph :return: a pair of mutual-extremal vertexes (s,t) \u0026#34;\u0026#34;\u0026#34; s = np.random.choice(G.nodes) while True: level_set = level_set_algo(G,s) # find th extremal w.r.t root t = np.random.choice(level_set[-1]) level_set_n = level_set_algo(G,t) if len(level_set) == len(level_set_n): return (s,t) s = t Phase 2: Constructing the level sets\nCode:\ndef level_set_algo(G, root) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; find the level set with respect to a root vertex :param root: root vertex, the starting point :return: level set, ordered by distance \u0026#34;\u0026#34;\u0026#34; pathes = nx.single_source_shortest_path(G,root) pathes_length = [len(route) - 1 for route in pathes.values()] pathes_nodes = list(pathes.keys()) level_set = [] for i, vertex in enumerate(pathes_nodes): if pathes_length[i] == pathes_length[i-1]: level_set[-1].append(vertex) else: level_set.append([vertex]) if sum([len(i) for i in level_set]) != len(G.nodes): nx.draw(G, with_labels=True) plt.savefig(\u0026#39;test.png\u0026#39;) print(\u0026#34;bla\u0026#34;) return level_set **Phase 3: Find the inital seperator **\nCode\ndef single_partition(G, ALPHA=4.0) -\u0026gt; dict: \u0026#34;\u0026#34;\u0026#34; single layer level set based partition algorithm The emhanced method of GeorgeLiu Algo with cost function (Ashcraft, 2016) :return: the partition result, grouped by Black, White and Seperator \u0026#34;\u0026#34;\u0026#34; s,_ = diameter_pair_algo(G) level_set = level_set_algo(G,s) cost = np.Inf partition = {} for i in range(1,len(level_set)-1): # construct partition set B = level_set[:i] W = level_set[i+1:] S = level_set[i] cur_cost = cost_1(B,W,S, ALPHA) if cur_cost \u0026lt; cost: partition[\u0026#34;B\u0026#34;] = B partition[\u0026#34;W\u0026#34;] = W partition[\u0026#34;S\u0026#34;] = S cost = cur_cost # when the len(level_set) \u0026lt; 3: if len(partition) \u0026lt; 3: assert len(partition) \u0026lt; 2, \u0026#34;check\u0026#34; partition[\u0026#34;B\u0026#34;] = [level_set[0]] partition[\u0026#34;S\u0026#34;] = level_set[1] partition[\u0026#34;W\u0026#34;] = [[]] return partition return partition **Phase 4: Recursive excecution **\nCode\ndef ND_solve(G,p) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; main function to excecute the partition recursively :param p: the list of reordered vertex index :return: the reordered index of vertexes \u0026#34;\u0026#34;\u0026#34; # filtering the isolated vertex iso_nodes = singleton(G) p += iso_nodes for node in iso_nodes: G.remove_node(node) if len(list(G.nodes)) \u0026lt;= 2: p += list(G.nodes) return p partition = single_partition(G) B = [item for sublist in partition[\u0026#34;B\u0026#34;] for item in sublist] W = [item for sublist in partition[\u0026#34;W\u0026#34;] for item in sublist] seperator = partition[\u0026#34;S\u0026#34;] sub_graphs = [G.subgraph(c).copy() for c in [W,B]] ND_solve(sub_graphs[0],p) ND_solve(sub_graphs[1],p) p += seperator return p ","permalink":"http://localhost:1313/posts/nested-dissection/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eRevisitting the sparse matrix technology.\u003c/p\u003e","title":"Note | Nested Dissection Algorithm"},{"content":"Monte Carlo Tree Search Summary Vanilla MCTS http://www.incompleteideas.net/609%20dropbox/other%20readings%20and%20resources/MCTS-survey.pdf\nSearching Process Starting from $S_0$ :\nSelection:\nTwo statistic information:\nVisit count $N(V)$ Win count $Q(V)$ Selection the possible action by Upper Confidence Bound for Tree (UCT): $$ UTC(v\u0026rsquo;) = \\frac{Q(V\u0026rsquo;)}{N(V\u0026rsquo;)}+c\\sqrt{\\frac{InN(V)}{N(V\u0026rsquo;)}} $$\n​\tUntil the most urgent expandable node is reached. A Expandable Node is the node that has one or mode child node haven\u0026rsquo;t been explored.\nExpansion: Adding the child node to the current node Rollout: Start from the current leaf node, taking a random sequence of actions to play the game until reaching to the end. Back-propogation: Backup the simulation result through the selected nodes to update their statistics Note:\nThe UCT score could be treated as two components: The exploitation part and the exploration part In exploitation part: $Q(v)$ is the rewards of all play out that pass the node $v$ , $N(v)$ is the visit count. MCTS in Alpha Go https://www.nature.com/articles/nature16961\nNetworks 2 policy networks $P_\\sigma (a|s)$ Supervised Learning policy network\nInput: Simple representation of the board state Output: Probability distribution over all legal movement Goal: Maximize the likelihood of the huaman move a selected in State s $P_\\pi (a|s)$ Reinforcemet Learning policy network\nIdentical Structure as $P_\\sigma$ Goal: Maximize the expected outcome 1 value network $V_\\theta(s) $ RL value network Input: State preresentation Output: outcome from the current position Searching Process Selection:\nThree Statistic Info on each node (s, a):\nVisit count\nPrior Probability, predicted by $p_\\sigma(a|s)$\nAction Value $Q(s,a)$: Average evaluation of all simulation passing through that each\nTraversing the tree by selecting the edge with max mark, where mark is $$ Q + u(P) $$\nExpansion:\nThe expanded node will be processed by $P_\\sigma $, generating the prior probability of each poential actions. Evaluation:\nThe Leaf node will be evaluated by two ways $$ V(S_L) = (1-\\lambda)v_\\theta(s_L) + \\lambda z_L $$ Evaluating the node by $V_\\theta$ Evaluating the node by continuing playing the game from the state $$S_L$$ (Same as before), while using $$P_\\pi$$ to sample actions. At the end of the game, using an evaluation function. Backup:\nUpdate the visit count and mean evaluation recursively. MCTS in Alpha Go Zero https://discovery.ucl.ac.uk/id/eprint/10045895/1/agz_unformatted_nature.pdf\nNetwork One network $f(\\theta)$ to replace the value evaluate net and policy net in the previous one Input: A sequence of representation of board position: raw board representation s of the position and its history Ouput: $Pr(a|s)$ Probability of each action, Vector $V(s,a)$ Evalution of current $(s,a)$, Scalar Searching Process Selection:\nSame as before, where $$ U(s,a) \\propto \\frac{P(s,a)}{1+N(s,a)} $$ Expansion and Evaluation:\nInstead of continue exceuting the game, the evaluation of the expanded node is directly predicted by $f(\\theta)$ , same for the prior probability Evaluation:\nAction-values Q are updated to track the mean of all evaluations V in the subtree below that action MCTS in MuZero https://www.nature.com/articles/s41586-020-03051-4\nWithout the simulator: No state transitions No Terminate states No actions restriction Networks All parameters are trained jointly\nRepresentation function h:\nEncoding the history over board states into the internal state $s$ $$ s = h_\\theta(o_1,\\cdots,o_t) $$ Perdiction function f :\nsame architecture as AlphaZero $$ p_k,v_k = f_{\\theta}(s_k) $$\nDynamics function g:\nMirror the structure of MDP, a recurrent process $$ r_k,s_k=g_{\\theta}(s_{k-1},a_k) $$ Searching process Observation Encoding by representation function $h(s)$\nSelection:\nEach node contains 5 statistic info:\nVisit count Policy Mean value Reward State transistion (Internal root state) According to probabilistic upper confidence tree bound\nExpansion:\nCreate the new node Reward and state are from the dynamic function $r\u0026rsquo;,s\u0026rsquo;=g_{\\theta}(s,a\u0026rsquo;)$ Policy and Value are from predcition function $p\u0026rsquo;,v\u0026rsquo;=f_{\\theta}(s\u0026rsquo;)$ Mean value and visit cound are initialized as 0 Backup\nMCTS in Sampled Alpha Zero http://proceedings.mlr.press/v139/hubert21a/hubert21a.pdf\n","permalink":"http://localhost:1313/posts/monte-carlo-tree-search-summary/","summary":"\u003ch1 id=\"monte-carlo-tree-search-summary\"\u003eMonte Carlo Tree Search Summary\u003c/h1\u003e","title":"Note | Monte Carlo Tree Search Summary"},{"content":"Reinforcement Learning Algorithms Summary 1. The connection between Dynamic Programming(DP), Monte-Carlo Method(MC), and Temporal Difference(TD): 1.1 Dynamic Programming Taking Policy iteration as an example, the Bellman expectation equation is the key in policy iteration. It is made of two parts: Policy evaluation, and policy improvement. In the policy evaluation stage, the method utilizes the Bellman expectation equation to iteratively calculate the state value for the current state until the value is converged. $$V_{\\pi}(s)=\\sum_a \\pi(a|s)\\sum_{s\u0026rsquo;,r}p(s\u0026rsquo;,r|s,a)[r+\\gamma v_{\\pi}(s\u0026rsquo;)]$$\nIn the policy improvement stage: $$\\pi(s) = argmax_a \\sum_{s\u0026rsquo;,r}p(s\u0026rsquo;,r|s,a)[r+\\gamma V(s\u0026rsquo;)]$$\nNote this is a model-based method since each step needs to know P, the transition probability. 1.2 Monte Carlo Method The model is unknown, the value function is estimated by sampling in each episode. Update Q value at each end of episodes: $$Q(s,a) = Q(s,a) +\\alpha[\\mathbb{E}[R(s,a)]-Q(s,a)]$$\nwhere $\\alpha$ is the learning rate, $\\mathbb{E}[R(s,a)]$ is the mathematical expectation of $(s,a )$ within one episode.\nMonte Carlo Method uses the practical cumulative rewards as the estimation of the action state value $Q(s,a)$ 1.3 Temporal Difference Temporal difference utilizes the advantage from both Monte Carlo and Dynamic programming methods. Time Difference learns directly from episodes of experience like MD, while experiences are from incomplete episodes by backup methods like DP. 2. Tabular Q-Learning 2.1 Algorithm Algorithm 1: Tabular Q learning\nInitialize Q table\nInitialize probability $\\epsilon \\longleftarrow \\epsilon_{max}$\nRepeat (for each episode):\nInitialize state $s$\nRepeat (for each step of the episode)\nWith probability $\\epsilon$ select a random action $a$ otherwise select action $a = \\argmax_aQ(s)$\nTake action $a$, observe reward $r$, next state $s'$\n$Q(s,a)\\longleftarrow Q(s,a)+\\alpha [r(s,a)+\\gamma\\max Q(s\u0026rsquo;)-Q(s,a)]$\n$\\epsilon \\longleftarrow \\epsilon * decaying\\ factor$\n$s\\longleftarrow s'$\nUntil $s$ is terminate\n2.2 Temporal Difference In Q value update function: $Q(s,a)\\longleftarrow Q(s,a)+\\alpha [r(s,a)+\\gamma\\max Q(s\u0026rsquo;)-Q(s,a)]$\nwhere $r(s,a)+\\gamma\\max Q(s\u0026rsquo;)$ is the TD target, and $r(s,a)+\\gamma\\max Q(s\u0026rsquo;)-Q(s,a)$ is the TD difference. By using temporal difference, we do not need to update the value at the end of each episode, while updating at each step by utilizing the Bellman optimality equation (TD target) 3. Deep Q Learning 3.1 Compared with Q learning In tabular Q learning, the mapping relation $(s,a)\\longrightarrow Q$ are stored as a table. It could lead to a huge waste of time, or even dimensional disaster when searching the related value if $(s,a)$ pairs are too much. Deep Neural Network is introduced to replace the Q table in DQN 3.2 Two problems Two problems in DQN if only introducing a single neural network: Training neural network requires the stochastic samples, while trajectories collected in the environment are highly correlated. The target state value is also estimated by the network. It could be unstable since the weight in the network is always updated To solve these problems, two mechanisms were introduced in DQN: Experience Replay: Randomly choosing a batch of experience$(s,a,s\u0026rsquo;,r)$ from the experience pool at the end of each episode, breaking the correlation between training samples. Fixed Q targets: The second neural network was introduced to specifically estimate the target state value. The update in the target net is relatively slower than the main net, synchronizing the parameters with the main net after every fixed time step. 3.3 Loss functions Main Goal $$Loss = Q^(s,a)-Q(s,a)\\Q^(s,a)=R(s,a)+max_{a\u0026rsquo;}\\hat{Q}(s\u0026rsquo;,a\u0026rsquo;)$$\n3.3 Two networks: Policy net $Q$, the input is the state, outputs are state-action values for different possible actions. This is used to choose the optimal action at each step $a_t = \\argmax_a Q(s_t,a;\\theta)$ target net $\\hat{Q}$, same structure but different task. This network is used for estimating the optimal state-action values by $q=\\max_{a\u0026rsquo;}\\hat{Q}(s\u0026rsquo;,a\u0026rsquo;;\\theta^{-})$ 3.4 Algorithm 3.5 Tips in code implementation: When estimating the optimal state value, the next state from the step is needed to evaluate the next state value, the next state could be null since the experience were randomly sampled from the pool and the current state could be the last step. Note, the next state info in (next_state, reward, done, info) pairs returned by the environment at this time could still be some random float even if the current state is the final state. 3.6 Further improvement Double DQN Prioritized Replay DQN \u0026hellip;\u0026hellip; 4. Vanilla Policy Gradient 4.1 Policy optimization Not like Q learning, policy optimization is on-policy method. In reinforcement learning, what we care is about how to choose action under the given state, namely, policy $\\pi(a|s)$. In Q learning methods, this process is determined by the operation $s\\stackrel{\\argmax_aQ(s,a)}{\\longrightarrow}a$. The policy is indirectly found by repeating this operation with different time steps. While in policy optimization, the neural network is trained to directly estimate the policy. Another neural network is needed to estimate state value, this is used for calculating the advantage function and guide policy to better update. 4.2 Loss function in policy net We want to maximize the expected total return by improving the policy. $$J(\\pi_\\theta) = \\mathbb{E}{\\tau\\sim\\pi}[R(\\tau)]\\\\theta{k+1} = \\theta_k + \\nabla_{\\theta}J(\\pi_\\theta)\\tag{gradient ascent}$$\nA simplified expression can be obtained after derivation on$\\nabla_{\\theta}J(\\pi_{\\theta})$ $$\\nabla_{\\theta}J(\\pi_{\\theta}) = \\mathbb{E}{\\tau\\sim\\pi{\\theta}}[\\sum_{t=0}^{T}\\nabla_{\\theta}\\log\\pi_{\\theta}(s_t|s_t)\\hat A_t]$$\nwe could utilize Monte-Carlo approximation to calculate the equation, by averaging the trajectory sum at each episode. Hence we got: $$\\nabla_{\\theta}J(\\pi_{\\theta})\\approx\\hat{g} = \\frac{1}{D}\\sum_{\\tau\\in D}\\sum_{t=0}^T\\nabla_{\\theta}\\log\\pi_{\\theta}(a_t|s_t)\\hat A_t\\tag{1}$$\n4.3 Improving the loss function $R(\\tau)$ in equation (1) is the most basic expression to evaluate how good a policy is. However, in MDPs**, the goodness of action only affects the rewards in the future (after that action), not relating to the rewards before**, and not relating to the whole trajectory. Hence, $R(\\tau)$ could be replaced by other improved equations, denoted as $\\phi_t$ $$\\nabla_{\\theta}J(\\pi_{\\theta}) = \\mathbb{E}{\\tau\\sim\\pi{\\theta}}[\\sum_{t=0}^{T}\\nabla_{\\theta}\\log\\pi_{\\theta}(s_t|s_t)\\phi_t]$$\nReward-to-go: reward-to-go removes the rewards brought by earlier actions. $$\\nabla_{\\theta}J(\\pi_{\\theta}) = \\mathbb{E}{\\tau\\sim\\pi{\\theta}}[\\sum_{t=0}^{T}\\nabla_{\\theta}\\log\\pi_{\\theta}(s_t|s_t)\\sum_{t\u0026rsquo;=t}^TR(s_{t\u0026rsquo;},a_{t\u0026rsquo;},s_{t\u0026rsquo;+1})]$$\nBaseline is the method introduced to reduce the variance between different trajectories but not changing the expectation. The most common based line is the on-policy value function $V^{\\pi}(s_t)$. Extra: Expected Grad-Log-Prob ( EGLP ) lemma $$\\nabla_{\\theta}J(\\pi_{\\theta}) = \\mathbb{E}{\\tau\\sim\\pi{\\theta}}[\\sum_{t=0}^{T}\\nabla_{\\theta}\\log\\pi_{\\theta}(s_t|s_t)[\\sum_{t\u0026rsquo;=t}^{T}R(s_{t\u0026rsquo;}, a_{t\u0026rsquo;}, s_{t\u0026rsquo;+1})-V^{\\pi}(s_t)]]$$\nAdvantage function: advantage function is defined as discounted rewards - baseline estimated, in VPG, the advantage is: $$A(s,a)=Q(s,a)-V(s,a)=\\phi_t(s,a)$$\nAdding all together: The loss function in VPG is: $$L(\\theta) =\\mathbb{E}t[\\log\\pi{\\theta}(a_t|st)\\hat{A}_t]$$\n4.4 Loss function in target net Another network is needed to estimate the value function since it was used in advantage function. The loss is calculated by mean square error and the net is fitted by gradient descent. $$target\\ value\\ loss=MSE(V^{\\pi}(s_t), \\hat{R}_t)$$\n4.5 Algorithm 4.5 Generalize Advantage Estimate (GAE) $$\\hat{A_t}^{GAE(\\gamma,\\lambda)} = \\sum_{l-1}^{\\infty}(\\gamma\\lambda)^l\\delta_{t+1}^V\\=\\sum_{l=1}^{\\infty}(r_t + \\gamma V(s_t +\\gamma V(s_t +l+1)-V(s_{t+l})))$$\n5. Proximal Policy Optimization 5.1 Drawbacks of basic VPG: Training data sets are collected by interacting with the environment, and data distribution over states and rewards are constantly changing, making the prediction unstable. Very high sensitivity of hyper parameters. 5.2 Loss function $$\\mathbb{E}t[L_t^{CLIP}(\\theta)-c_1L_t^{VF}(\\theta)+c_2S[\\pi{\\theta}(s_t)]]\\tag{1}$$\nwhere the first part of equation 1 is the central objective function of the policy net: $$L^{CLIP}(\\theta) = \\mathbb{E_t}[\\min(\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}\\hat{A_t},\\ clip(\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)},1-\\epsilon,1+\\epsilon)\\hat{A_t}]\\tag{2}$$\nThe first part is the normal policy gradient objective which pushes the policy towards actions that yield a high positive advantage over the based line The second is nothing but new but adding a clipping operation, making the probability of actions change under two conditions. (The advantage function is noisy and we do not want to destroy our policy based on on a single estimate!!): If the advantage is positive (action is good), it clips the objective function if $\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}$ is too large since we don\u0026rsquo;t want to overdo the action too much. If the advantage is negative (action is bad), it flattens the objective function if $\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}$ is near zero since we also don\u0026rsquo;t want to reduce these action probability to zero min operator plays its role when the $\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}$is big but making the policy worse, the min operator will choose the normal policy objective function instead of clipped version since this is the only region that the normal version is lower than the clipped version The second part of equation 1 is the loss function of the target net, which is basically in charge of updating the baseline network ($\\hat{A}_t$) $$L_t^{VF}(\\theta)=\\mathbb{E_t}[\\hat{R}_t - V_t(s_t)] \\tag{3}$$\nThe value estimation network shares a large portion of parameters with the policy estimate network (similar feature pipelines), hence we put losses into one equation and the\nThe third part of the equation is the entropy bonus term which ensures the agent does enough exploration during train\nthird part of equation 1 : entropy bonus\nto transmit one bit of information means to reduce the recipient\u0026rsquo;s uncertainty by a factor of 2\nsuppose $p_i$ is the probability of event $p$: $$Entropy:H(p)=p_1\\times\\log_2 \\frac{1}{p_1} +p_2\\times\\log_2 \\frac{1}{p_2}+p_3\\times\\log_2 \\frac{1}{p_3}+\u0026hellip;\u0026hellip;\\=-\\sum_i p_i\\log_2(p_i)$$\nIt measures average amount of information that you get from one sample drawn from a given probability distribution. It tells you how unpredictable that probability distribution is. $$L^{VF}(\\phi) = \\frac{1}{N}\\sum$$\n","permalink":"http://localhost:1313/posts/reinfoce/","summary":"\u003ch1 id=\"reinforcement-learning-algorithms-summary\"\u003eReinforcement Learning Algorithms Summary\u003c/h1\u003e","title":"Note | Reinforcement Learning Algorithms Summary"},{"content":"Markov Property (MP) Markov Property (MP) The probability of reaching S’ from S only depends on S, not on the history of earlier states Fundamental of Bellman Equations (mentioned later) Markov Decision Processes (MDPs) ![](https://datawhalechina.github.io/easy-rl/chapter2/img/2.2.png) The mathematical description of reinforcement learning is based on Markov Decision Process, which can be described as tiple: (S, A, R, P, ρ0)\nwhere S：set of all possible states\nA: set of all possible actions\nR: rewards function\nP: state transition function: P(s’ | s, a ) probability of s’ if take action a in state s\nρ0：The initial state distribution\nDiscounted Return Trajectory trajectory τ is the set of states and actions τ = (s0, a0, s1, a1, · · · )\nReward and Return The reward is the encouragement of a single step while the return is the cumulative rewards on a whole trajectory Usually, we will consider the discounted factor on the return, hence: $$ R(\\tau) = \\sum_{t=0}^{\\infty}\\gamma^t r_t $$\nWhy do we need discounted factor ?\nCash now is better than cash later\nValue Function State Value function Vπ(s)​ To estimate how good it is for the agent to be in a given state under policy π​​ Vπ(s) = Eτ ∼ π[R(τ) | s0 = s]\nAction Value function Qπ(s, a)\nTo estimate how good it is for the agent to be in a given state and action under policy π Qπ(s, a) = Eτ ∼ π[R(τ) | s0 = s, a0 = a]\nBellman Equation It is frequent to estimate the value function in reinforcement learning. Bellman equation is the method to implement. The basic idea behind Bellman Equation is : Current Value = Current Reward + Future Value Recursive Relation in Reinforcement Learning A fundamental property of value functions used throughout reinforcement learning is that it satisfy particular recursive relationship. The Backup Operation transfer value information back to a state/state-action pair from its successor states/state-action pairs. Backup Diagram As the above diagram illustrated, the calculation of state-value function can be decomposed into two steps:\nBefore derivation: black dots stand for state, action pairs, white dots stands for action. Lines in B stands for policy probability, lines in C stands for states transition probability.\nIn diagram B:\nVπ(s) = ∑a ∈ Aπ(a|s)Qπ(s, a)\nIn diagram A: Qπ(s, a) = R(s, a) + γ∑s′ ∈ SP(s′|s, a)vπ(s′) ​ Merging equation A and B, we get one form of Bellman Equation for Vπ Vπ(s) = ∑a ∈ Aπ(s|a)(R(s, a) + γ∑s′ ∈ SP(s′|s, a)vπ(s′))\nSummary Bellman Equation(s) defines a connection between the current state and future state\nGiven the simplified form of Bellman Equations\n$$ \\begin{cases}V^\\pi(s)=\\mathbb{E}[r(s,a)+\\gamma V^\\pi(s\u0026rsquo;)]\\Q^\\pi(s,a)=\\mathbb{E}[r(s,a)+\\gamma \\mathbb{E}[Q^\\pi(s\u0026rsquo;,a\u0026rsquo;)]]\\V^(s)=\\max_{a}\\mathbb{E}[r(s,a)+\\gamma V^(s\u0026rsquo;)]\\Q^(s,a)=\\mathbb{E}[r(s,a)+\\gamma \\max_{a\u0026rsquo;}Q^(s\u0026rsquo;,a\u0026rsquo;)]\\end{cases} $$\n","permalink":"http://localhost:1313/posts/markov-property/","summary":"\u003ch1 id=\"markov-property-mp\"\u003eMarkov Property (MP)\u003c/h1\u003e","title":"Note | Markov Decision Processes"},{"content":"Overview Normal Equation is a method in parallel with gradient descent algorithm to minimize the cost function J.\nDiffer from the gradient descent, normal equation does not need iterate calculation, but directly calculate the stagnation points of the cost function. Since this is an analytical solution, it also has some limits. Below is a comparison between these two methods:\nGradient Descent Normal Equation Need to choose learning rate $\\alpha$ Does not need Multiple iteration One time calculation Works well when n is large Slow if n is very large Suits for all kinds of models Only suitable for linear regression Method Say the dataset has m examples, each example contains n features:\nPut all features into a “m x (n+1)” matrix, (one more column for $x_0$, always =1 ) $$ X=\\begin{bmatrix}1\u0026amp;x^{(1)}_1\u0026amp;x^{(1)}2\u0026amp;\\cdots\u0026amp;x^{(1)}n\\\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\1\u0026amp;x_1^{(m)}\u0026amp;x_2^{(m)}\u0026amp;\\cdots\u0026amp;x_n^{(m)}\\end{bmatrix} $$ where the cost function J is: $$ J(\\theta)=\\frac{1}{2m}\\sum{i=1}^m(h\\theta(x^i)-y_i)^2 $$\n$$ = \\frac{1}{2m}\\sum_{i=1}^m(\\theta^Tx_i-y_i)^2 \\href{https://duanwenbo.github.io/2021/04/01/ML-Learning-Note\u0026mdash;polynomial-regression-and-feature-scaling/#more}{\\ previous\\ derive} $$\n$$ = \\frac{1}{2m}(X\\theta-Y)^T(X\\theta-Y)\\href{https://blog.csdn.net/melon__/article/details/80589759}{\\ further\\ derive} $$\nTo find the converge solution, let: $$ \\nabla_{\\theta}J(\\theta)=0 $$ Hence, the solution is: $$ \\theta=(X^TX)^{-1}X^TY $$\nNon-invertible ? Since we used the transform matrix of X, what if the matrix is non-invertible? Below are two conditions in normal equation that may cause the non-invertibility.\nWhen it appears two linear correlation features, like meter and inch.\nSolution: Reduce one.\nWhen the number of features is greater than the number of examples\nSolution: increase the datasets or decrease the considered features.\n","permalink":"http://localhost:1313/posts/normal-equation/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eNormal Equation is a method in parallel with gradient descent algorithm to minimize the cost function J.\u003c/p\u003e","title":"Note | Normal Equation"},{"content":"Linear Regression with multiple variables It is common to consider more than one features when making a prediction. For example when predicting the price of a house:\nHence more generally hypothesis function can be written as: $$ h_\\theta(x)=\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3+\u0026hellip;+\\theta_n x_n $$ $$ =\\theta^Tx $$ Where $\\theta$ is $$ \\begin{bmatrix}\\theta_0\\ \\theta_1\\ \\vdots \\ \\theta_n \\end{bmatrix} $$ Also more generally, gradient descent algorithm can be written as: $$ \\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum^m_{i=1}[h_\\theta(x^{(i)}-y^{(i)})]x_j^{(i)} $$ $$ (simutaneously\\ update\\ \\theta_j\\ for\\ j=0,\\cdots,n) $$\nHowever, it also comes with some problem:\nThe choice of learning rate\nmay affect the speed of converge, or even can not converge.\nThe scale of number of examples and features may affect the speed of algorithm\nThe common linear regression is a straight line that may can not fit the data well\nFeature Scaling When there is a big magnitude difference between different features in a cost function, it could take a lot of time to iterate to find the converging point, for example:\nBy using the feature scaling, we aim to scale these different features to a similar range (roughly between -1 to 1). The common method of featuring scaling is mean normalization:\nMean normalization $$ X_{norm} = \\frac{x_n - \\mu_n}{s_n} $$\nWhere\n$\\mu_n$ is the average value $S_n$ is the range of the feature (maximum - minimum) Polynomial Regression As just mentioned, the common linear regression is a straight line that may can not fit the data well, some times we need curve to fit the data.\nFor example, we may want a quadradic function $h_\\theta(x)=\\theta_0 +\\theta_1 x_1 + \\theta_2 x^2_2$. Assuming: x_2 = x_2^2, to covert the quadratic function to a linear model which we are more familiar with\nNote: It is obvious that we need to scale the feature in polynomial regression since the features are more different from each other .\n","permalink":"http://localhost:1313/posts/scaling/","summary":"\u003ch2 id=\"linear-regression-with-multiple-variables\"\u003eLinear Regression with multiple variables\u003c/h2\u003e\n\u003cp\u003eIt is common to consider more than one features when making a prediction. For example when predicting the price of a house:\u003c/p\u003e","title":"Note | Polynomial Regression and Feature Scaling"},{"content":"Overview In the linear regression prediction, we want to find a hypothesis function to predict the future outcome. The method in supervised learning is by using loads of training data sets and a learning algorithm to let the result of the hypothesis function close to the real value as possible as we can.\nThe process can loosely be represented by the following flowchart:\nTraining sets are the data we got from the previous experience, which contains the input feature (X), and the training example(Y). It can be represented by $$ (x^{(i)},y^{(i)}) $$ where *i *is the index of the training sets\nThe hypothesis or saying, prediction function is a linear regression function: $$ h_{\\theta}(x)=\\theta_0 + \\theta_{1}x $$ Where $\\theta_0$ and $\\theta_1$ are the parameters that we look for to minimize the cost function.\nCost Functiom In order to let the result of the hypothesis function as close to the real result as possible, we need to find the specific $\\theta_0$and $\\theta_1$, and we have to try different values for these two variables. To normalize and evaluate output results with different parameter values, we use the cost function: $$ J(\\theta_0, \\theta_1)=\\frac{1}{2m}\\sum^m_{i=1}[h_\\theta (x^i)-y^{(i)}]^2 $$ Where\ni is the index of the data sets mis the number of data sets *$h_\\theta(x^{(i)})$*is the hypothesis output $y^(i)$ is the real example value Since it has a constant scalar output for each sets of training data, $J(\\theta_0, \\theta_1)$ can be seen as a scalar field. (always a convex bowl-shape field) Summary So far, we got hypothesis function: $$ h_\\theta(x)=\\theta_0 +\\theta_1 x $$ With parameters: $$ \\theta_0, \\theta_1 $$ Cost function is: $$ J(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum^m_{i=1}[h_\\theta(x^{(i)})-y^{(i)}]^2 $$ Goal is: $$ minimize\\ J(\\theta_0, \\theta_1) $$\nGradient Descent Algorithm basic idea start with a point keep finding the steepest direction of the current position and moving down a small step until end up at a minimum. formula $$ \\theta_j := \\theta_j -\\alpha \\frac{\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1) $$ $$ (for\\ j=0\\ and\\ j=1) $$ Note: The new value assignment for $\\theta_0$ and $\\theta_1$ have to be updated simultaneously.\nWhere\n:=” is the assignment operator, on the right side, $\\theta_j$ is the current parameter; on the left side, $\\theta_j$ is the next new value. The minus operation will be repeated until convergence. $\\alpha$ is the learning rate, or saying how long your every down step distance is, $\\frac{\\alpha}{\\alpha \\theta_j}J(\\theta_0, \\theta_1)$ is nothing but the partial derivative of the cost function. Conclusion derive $$ \\frac{\\partial}{\\partial \\alpha_j}J(\\theta_0, \\theta_1) $$ $$ =\\frac{\\partial}{\\partial \\theta_j}[\\frac{1}{2m}\\sum^m_{i=1}[h_\\theta(x^{(i)})-y^{(i)}]^2] $$ $$ =\\frac{1}{2m}\\frac{\\partial}{\\partial\\theta_j}\\sum^m_{i=1}[\\theta_0+\\theta_1x^{(i)}-y^{(i)}]^2 $$ When j = 0: $$ =\\frac{1}{2m}\\frac{\\partial}{\\partial\\theta_0}\\sum^m_{i=1}[\\theta_0+\\theta_1x^{(i)}-y^{(i)}]^2 $$ $$ =\\frac{2}{2m}\\sum^m_{i=1}[\\theta_0 + \\theta_1 x^{(i)}-y^{(i)}] $$ $$ =\\frac{1}{m}\\sum^m_{i=1}[h_\\theta(x^{(i)})-y^{(i)}] $$\nWhen j =1: $$ =\\frac{1}{2m}\\frac{\\partial}{\\partial \\theta_1}\\sum^m_{i=1}[\\theta_0+\\theta_1x^{(i)}-y^{(i)}]^2 $$\n$$ =\\frac{2}{2m}\\sum^m_{i=1}[\\theta_0+\\theta_1x^{(i)}-y^{(i)}]\\cdot x^{(i)} $$\n$$ =\\frac{1}{m}\\sum^m_{i=1}[h_\\theta(x^{(i)})-y^{(i)}]\\cdot x^{(i)} $$\nTake the derived conclusions back to the algorithm, we now got the simplified algorithm to find a particular pair of ($\\theta_0$, $\\theta_1$) for our hypothesis function: $$ \\theta_0 :=\\theta_0 -\\alpha\\frac{1}{m}\\sum^m_{i=1}[h_\\theta(x^{(i)})-y^{(i)}] $$\n$$ \\theta_1 :=\\theta_1-\\alpha\\frac{1}{m}\\sum^m_{i=1}[h_\\theta(x^{(i)}) - y^{(i)}\\cdot x^{(i)} $$\nNote: update $\\theta_0$and$\\theta_1$ simultaneously.\nSome thoughts and questions Q: Since the cost function is a convex, scalar field in linear regression, and the goal is to find the minimum, why don’t we just let the gradient = 0 to find the minimum stationary point of this field? A:\nNot all functions can find the point where the value of zero that obtained according to the derivative. Sometimes, the value of the derivative at each point can be obtained, but the direct solution of the equation cannot be solved. Or when the amount of data is large, the inverse of the matrix is required, which is very resource-consuming. n general, it is more effective than linear algebra solutions for mega-problems. When you have thousands of variables (such as machine learning), this becomes more important as the dimensions increase. we need to teach the computer how to calculate the root of the derivative of function. Reference: https://www.quora.com/Why-do-we-need-a-gradient-descent-anyway-if-we-can-just-take-derivative-of-function-and-make-it-equal-to-0-thus-finding-minimum\nQ: How to choose the learning rate $\\alpha$ in the algorithm? How does it affect? A:\nFirstly, gradient descent can converge to a local minimum, with the learning rate fixed. As we approach a local minimum, gradient descent will automatically take smaller steps since the gradient is decreased at the same time If the rate is too small, gradient descent can be slow. If the rate is too large, gradient descent can overshoot the minimum. Momentum Momentum is a physic theory that can describe that as the iterative process continues, the learning rate is appropriately reduced in order to reach the extreme point more smoothly. It shows that the running state of the moment before has an impact on the moment. In physics, it means the cumulative effect of expressive force on time.\nIn the previous equation, the decrement of each time (saying v) is represented by: $$ v=-\\alpha\\cdot\\frac{\\partial}{\\theta_j}J(\\theta_0,\\theta_1) $$ Consider the decrement v as the current gradient descent amount $-\\alpha\\cdot\\frac{\\partial}{\\theta_j}J(\\theta_0,\\theta_1)$ and the last update amount v multiplied by a factor momentum between [0, 1]: $$ v=-\\alpha\\cdot\\frac{\\partial}{\\theta_j}J(\\theta_0,\\theta_1) +v\\cdot momentum $$ When the direction of the current decrement is the same as the direction of the previous decrement. The previous decrement will play an acceleration role in the current search.\nWhen the direction of the current decrement is opposite from the direction of the previous decrement. The previous decrement will play a deceleration role in the current search.\nReference: https://www.jianshu.com/p/58b3fe300ecb\n","permalink":"http://localhost:1313/posts/gradient-decent/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eIn the linear regression prediction, we want to find a hypothesis function to predict the future outcome. The method in supervised learning is by using loads of training data sets and a learning algorithm to let the result of the hypothesis function close to the real value as possible as we can.\u003c/p\u003e","title":"Note | Batch Gradient Descent Algorithm"},{"content":"Basic Method When learning the eigenvalue and eigenvector, we are commonly given an equation at the beginning $$ AX = \\lambda X \\tag{1} $$ Where\nA is the matrix X is the eigenvector $\\lambda$ is the eigenvalue Take an example Q: Find the eigenvalues and eigenvectors of the matrix $$ A = \\begin{bmatrix} 1\u0026amp;1\u0026amp;-2\\ -1\u0026amp;2\u0026amp;1\\ 0\u0026amp;1\u0026amp;-1 \\end{bmatrix} $$ A: To get the answer, firstly apply the equation (1) : $$ AX = \\lambda X \\tag{1} $$\nBefore solving the equation, there might be something awkward, since on the right-hand side of the equation, it’s matrix-vector multiplication; while on the left-hand side, it’s the scalar-vector multiplication.\nWe can rewrite the right-hand side as some kind of matrix-scalar multiplication, namely, using the identity matrix which has the effect of scaling any vector by $\\lambda$\nI is the identity matrix here, form like:\nHence: $$ (\\lambda I-A)X=0 \\tag{2} $$ In order to get a non-trivial solution, we get : $$ \\left| \\lambda I-A\\right| = 0 \\tag{3} $$ where equation (3) is also called characteristic function. Expanding equation (3): $$ \\begin{bmatrix}\\lambda -1\u0026amp;-1\u0026amp;2\\1\u0026amp;\\lambda -2\u0026amp;-1\\0\u0026amp;-1\u0026amp;\\lambda +1\\end{bmatrix} = det(\\lambda I -A)=\\lambda^3 -2\\lambda^2 -\\lambda +2=0 \\tag{4} $$ Solving equation(4) we got eigenvalues as: $$ \\begin{cases}\\lambda_1 = 2\\ \\lambda_2 = 1\\ \\lambda_3 = -1\\end{cases} $$ Now we can find the related eigenvector respectively by taking eigenvalues back to equation (2): $$ \\begin{bmatrix}1-2\u0026amp;1\u0026amp;-2\\-1\u0026amp;2-2\u0026amp;1\\0\u0026amp;1\u0026amp;-1-2\\end{bmatrix}\\begin{bmatrix}e_1\\e_2\\e_3\\end{bmatrix}=0\\ (when\\ \\lambda=2) $$ hence: $$ \\frac{e_1}{-1}=\\frac{-e_2}{3}=\\frac{e_3}{-1} $$ Unless otherwise stated, the eigenvectors will always be presented in their ‘simplest’ form, so the matrix of the eigenvector can be written as: $$ \\begin{bmatrix}1\\3\\1\\end{bmatrix}\\ (when\\ \\lambda =2) $$ The other two eigenvector can be calculated similarly.\nWhat does it mean? Start from definition looking back to the equation (1) again: $$ AX=\\lambda X \\tag{1} $$\nOn the right hand side, A is a matrix, stands for a kind of linear transformation (rotation, stretching). On the left hand side, $\\lambda$ is a scalar Matrix A multiply by x means applying a transformation on the vector X (rotation or stretching), and the effect of this kind of transformation is equal to the scalar $\\lambda$ multiply by the vector X. (Only stretched) By finding the eigenvalue and eigenvector, we can find out which vectors (eigenvectors) can be stretched only by the matrix, and what’s the extent to which it’s stretched (eigenvalue.) ","permalink":"http://localhost:1313/posts/2021-03-13-eigenvector-and-eigenvalue-review/","summary":"\u003ch2 id=\"basic-method\"\u003eBasic Method\u003c/h2\u003e\n\u003cp\u003eWhen learning the eigenvalue and eigenvector, we are commonly given an equation at the beginning\n$$\nAX = \\lambda X \\tag{1}\n$$\nWhere\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA is the matrix\u003c/li\u003e\n\u003cli\u003eX is the eigenvector\u003c/li\u003e\n\u003cli\u003e$\\lambda$ is the eigenvalue\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"take-an-example\"\u003eTake an example\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eQ: Find the eigenvalues and eigenvectors of the matrix\u003c/em\u003e\n$$\nA = \\begin{bmatrix}\n1\u0026amp;1\u0026amp;-2\\\n-1\u0026amp;2\u0026amp;1\\\n0\u0026amp;1\u0026amp;-1\n\\end{bmatrix}\n$$\nA: To get the answer, firstly apply the equation (1) :\n$$\nAX = \\lambda X \\tag{1}\n$$\u003c/p\u003e","title":"Note | Eigenvector and Eigenvalue Review"}]